{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2cc060",
   "metadata": {},
   "source": [
    "\n",
    "<a id='chap-tpdeeplearning3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aae7a5",
   "metadata": {},
   "source": [
    "# Travaux pratiques - Deep Learning avec Keras\n",
    "\n",
    "L’objectif de cette séance de travaux pratiques est de découvrir la bibliothèque\n",
    "[Keras](https://keras.io/) et ses fonctionalités pour la création et l’apprentissage\n",
    "de réseaux de neurones profonds. En particulier, nous allons reprendre les deux modèles\n",
    "vus précédemment (régression logistique et perceptron) pour montrer comment les\n",
    "implémenter avec Keras. Nous verrons également un premier modèle simple de réseau\n",
    "de neurones profonds convolutif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b95102",
   "metadata": {},
   "source": [
    "## Importation de Keras/TensorFlow\n",
    "\n",
    "Keras est une bibliothèque logicielle open-source écrite en Python pour l’apprentissage profond.\n",
    "Il s’agit en réalité d’une surcouche à [TensorFlow](https://www.tensorflow.org/?hl=fr), qui implémente\n",
    "les briques de base (opérations matricielles, couches, fonctions de transfert). TensorFlow gère\n",
    "notamment la possibilité d’exécuter un réseau de neurones sur le processeur (*CPU*) ou sur accélérateur\n",
    "graphique matériel (*GPU*).\n",
    "\n",
    "L’import de Keras s’effectue depuis TensorFlow :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bacdb5df-0cbe-4122-a87a-ad30a0663f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pybind11 in /home/florian-andr/anaconda3/envs/jpn_florian/lib/python3.8/site-packages (2.13.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d3a0c49",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c07eae",
   "metadata": {},
   "source": [
    "En plus des fonctionnalités liées à l’apprentissage profond, `Keras` intègre des utilitaires\n",
    "pour charger et manipuler un certain nombre de jeux de données populaires, comme MNIST :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dbe32f72",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement du jeu de données MNIST\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# Conversion en encodage one-hot\n",
    "Y_train = keras.utils.to_categorical(y_train, 10)\n",
    "Y_test = keras.utils.to_categorical(y_test, 10)\n",
    "# Redimensionnement des images 28x28 en vecteurs d=784\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "# Assurez-vous que les images sont de type float pour la normalisation\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "# Normalisation entre 0 et 1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e913c",
   "metadata": {},
   "source": [
    "## Régression logistique avec `Keras`\n",
    "\n",
    "`Keras` propose plusieurs façons différentes de définir un réseau de neurones. La façon\n",
    "la plus courante pour les réseaux à propagation avant (*feedforward*), qui empilent les couches\n",
    "de façon séquentielle, est d’utiliser la classe Sequential (voir [sa documentation](https://keras.io/guides/sequential_model/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14b91765",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925cd5bf",
   "metadata": {},
   "source": [
    "`model` représente ainsi un réseau de neurones vide (pour l’instant). Il est possible\n",
    "d’ajouter des couches à l’aide de la méthode `add`. De nombreuses couches sont\n",
    "prédéfinies dans Keras, comme les couches entièrement connectées (couches linéaires\n",
    "dites `Dense`) ou les fonctions d’activation standard.\n",
    "\n",
    "Par exemple, le code ci-dessous ajoute une projection linéaire (couche entièrement\n",
    "connectée) de taille 10 au modèle, puis une activation de type *softmax*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2945e42",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "model.add(Dense(10,  input_dim=784, name='fc1'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea60db2",
   "metadata": {},
   "source": [
    "Le paramètre `input_dim` est nécessaire pour spécifier la dimension de l’entrée de la couche entièrement connectée.\n",
    "On peut ensuite visualiser l’architecture du réseau à l’aide de la méthode `summary()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3356a14d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fc1 (Dense)                 (None, 10)                7850      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7850 (30.66 KB)\n",
      "Trainable params: 7850 (30.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39fb75b6-211f-46c0-8748-20f66c4ef449",
   "metadata": {
    "hide-output": false
   },
   "source": [
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #\n",
    "=================================================================\n",
    "fc1 (Dense)                  (None, 10)                7850\n",
    "_________________________________________________________________\n",
    "activation (Activation)      (None, 10)                0\n",
    "=================================================================\n",
    "Total params: 7,850\n",
    "Trainable params: 7,850\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8590f2b",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Vérifier le nombre de paramètres du réseau à apprendre dans la méthode `summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5818e9df-da65-434d-bd60-1ce56e6b4637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fc1 (Dense)                 (None, 10)                7850      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7850 (30.66 KB)\n",
      "Trainable params: 7850 (30.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nb_parameters = model.summary()\n",
    "print(nb_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c157b-4609-465e-8b14-e106b2efc7c5",
   "metadata": {},
   "source": [
    "En plus de la définition de l’architecture, nous avons encore besoin de spécifier deux éléments à `Keras` avant d’entraîner\n",
    "notre modèle : une fonction de coût (*loss*) et une méthode d’optimisation.\n",
    "Ces paramètres sont spécifiés lors de la phase de *compilation* du modèle à l’aide de la méthode `.compile()`.\n",
    "Nous allons utiliser l’entropie croisée (`categorical_crossentropy`) comme fonction de coût et la descente de gradient stochastique\n",
    "(*stochastic gradient descent* ou `sgd`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b79b74c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4628dc5",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "À l’aide de la [documentation de la méthode .compile()](https://keras.io/api/models/model_training_apis/), déterminer à quoi correspond le paramètre `metrics=`.\n",
    "\n",
    "La boucle d’apprentissage du modèle sur les données d’apprentissage est automatisée par la méthode `.fit()` :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4154cdfb",
   "metadata": {},
   "source": [
    "Réponse : Le paramètre metrics correspond à la liste des métriques devant être évaluées par le modèle lors de l'entrainement et de la validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09933e85",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 11:59:21.480519: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 2ms/step - loss: 0.4800 - accuracy: 0.8684\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.9055\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.9117\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.9159\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.9179\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.9194\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.9206\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.9221\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.9215\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.9232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ed084622100>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=300, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc9e75",
   "metadata": {},
   "source": [
    "- `batch_size` correspond au nombre d’exemples utilisé pour estimer\n",
    "  le gradient de la fonction de coût.  \n",
    "- `epochs` est le nombre d’époques (*i.e.* passages sur l’ensemble\n",
    "  des exemples de la base d’apprentissage) lors de la descente de\n",
    "  gradient.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93834ca3",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "Pour les fonctions de coût de classification, Keras attend par convention que les étiquettes\n",
    "(*labels*) données pour la supervision soient au format *one-hot encoding*.\n",
    "\n",
    "L’évaluation des performances du modèle sur le jeu de test est également automatique, en fonction de la métrique choisie lors de la compilation, grâce à la méthode `.evaluate()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5514cdc2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27.43\n",
      "accuracy: 92.24\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(f\"{model.metrics_names[0]}: {scores[0]*100:.2f}\")\n",
    "print(f\"{model.metrics_names[1]}: {scores[1]*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc09696",
   "metadata": {},
   "source": [
    "Le premier élément de la liste `scores` correspond à l’erreur de test (valeur de la fonction de coût sur\n",
    "`(X_test, y_test)`) tandis que le deuxième élément correspond au taux de bonne classification (*accuracy*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35dbcb",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Comparer les performances obtenues par cette régression logistique implémentée avec Keras avec\n",
    "celles obtenues lors du premier TP. Conclure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5db3de",
   "metadata": {},
   "source": [
    "On remarque que cette régression logistique implémentée avec Keras obtient les mêmes résultats en termes d'accuracy que le test effectué sur le premier TP avec le premier réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93616c4",
   "metadata": {},
   "source": [
    "## Perceptron avec Keras\n",
    "\n",
    "Nous pouvons maintenant enrichir ce modèle de régression logistique en insérant\n",
    "une couche de neurones cachés complètement connectée ainsi qu’une\n",
    "fonction d’activation non linéaire de type sigmoïde entre la couche\n",
    "d’entrée et la couche de sortie. Ce nouveau modèle va ainsi correspond\n",
    "au réseau de neurones à une couche cachée (perceptron) vu précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b2040",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Créer un nouveau modèle `model = Sequential()` et le compléter en lui\n",
    "ajoutant :\n",
    "\n",
    "- une couche entièrement connectée avec 100 neurones cachés,  \n",
    "- une activation sigmoide,  \n",
    "- une couche entièrement connectée avec 10 neurones de sortie,  \n",
    "- une activation softmax,  \n",
    "\n",
    "\n",
    "de sorte à retrouver le *multi-layer perceptron* du TP précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e03989d7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "\n",
    "# Première couche entièrement connectée (100 neurones cachés, activation sigmoïde)\n",
    "model.add(Dense(100, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "# Deuxième couche entièrement connectée (10 neurones de sortie, activation softmax)\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6803b",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Combien ce modèle a-t-il de paramètres ? Justifier le calcul et vérifier à l’aide de la méthode `.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "616299b2-c218-4e39-8121-497879b12780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2389e47",
   "metadata": {},
   "source": [
    "Réponse : ce modèle comporte maintenant 79510 paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e021fe0d-8cce-4410-9e65-c1e6dae13781",
   "metadata": {},
   "source": [
    "L’entraînement de ce nouveau modèle s’effectue de façon strictement identique à ce que nous avons vu précédemment.\n",
    "En effet, Keras s’inspire de l’interface de scikit-learn : tous les modèles se manipulent de la même façon une fois\n",
    "compilés. L’algorithme de rétropropagation du gradient et l’optimisation par descente de gradient sont implémentés\n",
    "dans Keras et il n’est plus nécessaire de les écrire à la main."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd11cf5",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Compiler le perceptron multi-couche puis l’entraîner sur la base d’apprentissage de MNIST. On utilisera\n",
    "la même fonction de coût et le même optimiseur que pour la régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d65cd822-1d44-46a3-bf4c-3d1eb4aa61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535376ab",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Évaluer les performances du perceptron multi-couche sur le jeu de test de MNIST et comparer\n",
    "à celles obtenues lors du précédent TP. Conclure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4356dd6-4a43-4278-95d3-727043834804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 283.87%\n",
      "Accuracy: 9.80%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores_mlp = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Loss: %.2f%%\" % (scores_mlp[0]*100))\n",
    "print(\"Accuracy: %.2f%%\" % (scores_mlp[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6bd54",
   "metadata": {},
   "source": [
    "Réponse : l'accuracy est de 12.38%, ce qui correspond aux valeurs obtenues sur les premiers epochs du tp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38dfbff",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "À l’aide de la [documentation de Keras](https://keras.io/api/layers/core_layers/dense/), déterminer\n",
    "comment sont initialisés les paramètres du modèle pour les couches entièrement connectées.\n",
    "\n",
    "Une fonctionnalité utile de Keras est la possibilité de sauvegarder des modèles sur le disque pour les partager\n",
    "ou les réutiliser plus tard. Cette opération se fait simplement à l’aide de la méthode `.save()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f98a60d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian-andr/anaconda3/envs/jpn_florian/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('MLP.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f581e",
   "metadata": {},
   "source": [
    "Il est possible de charger un modèle sur le disque à l’aide de la fonction `load_model` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "adf0242c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('MLP.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a8d3d",
   "metadata": {},
   "source": [
    "## Réseaux de neurones convolutifs avec Keras\n",
    "\n",
    "Pour cette dernière partie, nous allons passer du réseau entièrement connecté à un modèle convolutif.\n",
    "En effet, les réseaux de neurones convolutifs profonds (*Convolutional Neural Networks* ou CNN) sont\n",
    "particulièrement adaptés à la reconnaissance d’images.\n",
    "\n",
    "Les réseaux convolutifs manipulent des images multi-dimensionnelles en entrée (des tenseurs).\n",
    "Comme nous avions initialement transformé nos images en vecteurs, nous allons les redimensionner\n",
    "de sorte à ce que chaque observation du jeu de données MNIST soit bien une image carrée de 28 pixels\n",
    "de côté en niveaux de gris, c’est-à-dire de dimensions $ 28\\times 28\\times 1 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e0224b8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d485bd",
   "metadata": {},
   "source": [
    "Par rapport aux réseaux complètement connectés, les réseaux convolutifs\n",
    "utilisent les briques élémentaires suivantes :\n",
    "\n",
    "1. Des couches de convolution, qui transforment un tenseur d’entrée de\n",
    "  taille $ n_x \\times n_y \\times p $ en un tenseur de sortie\n",
    "  $ n_{x'} \\times n_{y'} \\times n_H $, où $ n_H $ est le nombre\n",
    "  de filtres choisi.  \n",
    "\n",
    "\n",
    "Keras implémente bien entendu par défaut les couches convolutives. Il s’agit de la classe `Conv2D`.\n",
    "Par exemple, une couche de convolution pour traiter les images d’entrée de MNIST peut être créée de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5208a56f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.convolutional.conv2d.Conv2D at 0x7ed084f2fc10>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "#Conv2D(..., kernel_size=(..., ...), activation=, input_shape=(input_shape), padding=...) \n",
    "Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=input_shape, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73a450",
   "metadata": {},
   "source": [
    "Dans l’instanciation de cette classe, on retrouve de nombreux arguments :\n",
    "\n",
    "- 32 correspond au nombre de filtres souhaité pour cette couche convolutive.  \n",
    "- (5, 5) sont les dimensions spatiales du noyau de convolution de chacun des filtres.  \n",
    "- `padding='same'` ajoute des 0 à l’image d’entrée de sorte à conserver la même taille en sortie qu’en entrée ($ n_x = n_x' $).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b1770",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "On remarque qu’il est possible de spécifier directement dans la couche de convolution\n",
    "la non-linéarité qui sera appliquée en sortie des activations. Dans notre cas,\n",
    "nous avons choisi d’appliquer une fonction d’activation sigmoide après la convolution.\n",
    "\n",
    "1. Des couches d’agrégation spatiale (*pooling*), afin de permettre une\n",
    "  invariance aux translations locales. Elles sont implémentées par la classe `MaxPooling2D`\n",
    "  de Keras :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ea0bac9",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x7ed084f2f7f0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "MaxPooling2D(pool_size=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18f766",
   "metadata": {},
   "source": [
    "- (2, 2) est la taille spatiale sur laquelle l’opération d’agrégation\n",
    "  est effectuée.  \n",
    "\n",
    "\n",
    "Ces deux briques élémentaires peuvent être ajoutées à n’importe quel modèle séquentiel en Keras à l’aide de la méthode `.add()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7945ae9b",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Implémenter un réseau de neurones convolutif reprenant l’architecture suivante, similaire à celle du modèle historique LeNet5 [[LBD+89]](#lecun1989backpropagation),\n",
    "illustré ci-dessous :\n",
    "\n",
    "<img src=\"LeNet5.png\" style=\"width:600;\">\n",
    "\n",
    "- Une couche de convolutions avec 16 filtres de taille\n",
    "  $ 3 \\times 3 $, suivie d’une non-linéarité sigmoïde puis\n",
    "  d’une couche de max pooling $ 2 \\times 2 $.  \n",
    "- Une couche de convolutions avec 32 filtres de taille\n",
    "  $ 3 \\times 3 $, suivie d’une non-linéarité sigmoïde puis\n",
    "  d’une couche de max pooling $ 2 \\times 2 $.  \n",
    "- Une seconde couche de convolution avec 64 filtres de taille\n",
    "  $ 3 \\times 3 $, suivie d’une non linéarité sigmoïde puis\n",
    "  d’une couche de max pooling $ 2 \\times 2 $.  \n",
    "- Comme dans le réseau LeNet, on considérera la sortie du second bloc\n",
    "  convolutif comme un vecteur, ce que revient à « mettre à plat » les\n",
    "  couches convolutives précédentes (`model.add(Flatten())`).  \n",
    "- Une couche complètement connectée de taille 100, suivie d’une sigmoide.  \n",
    "- Une couche complètement connectée de taille 10, suivie d’une activation softmax.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7c4105a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# Création du modèle\n",
    "model = Sequential()\n",
    "\n",
    "# Premier bloc convolutif: 16 filtres de taille 3x3, activation sigmoïde, suivi de max pooling 2x2\n",
    "model.add(Conv2D(16, (3, 3), activation='sigmoid', input_shape=(28, 28, 1), padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Deuxième bloc convolutif: 32 filtres de taille 3x3, activation sigmoïde, suivi de max pooling 2x2\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Troisième bloc convolutif: 64 filtres de taille 3x3, activation sigmoïde, suivi de max pooling 2x2\n",
    "model.add(Conv2D(64, (3, 3), activation='sigmoid', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Mise à plat (flatten) de la sortie des couches convolutives pour passer à une couche entièrement connectée\n",
    "model.add(Flatten())\n",
    "\n",
    "# Couche entièrement connectée de taille 100, activation sigmoïde\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "\n",
    "# Couche de sortie, complètement connectée, 10 neurones, activation softmax pour la classification multiclasse\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738caa6c",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Compiler puis entraîner le modèle sur le jeu d’apprentissage de MNIST. On reprendra la même fonction de coût et\n",
    "le même optimiseur que précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43aa34af-6342-455f-ac30-8b0e62f46d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.0247 - accuracy: 0.6381\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1276 - accuracy: 0.9617\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0797 - accuracy: 0.9752\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0612 - accuracy: 0.9805\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0492 - accuracy: 0.9845\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0411 - accuracy: 0.9869\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0342 - accuracy: 0.9891\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0303 - accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0259 - accuracy: 0.9920\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0228 - accuracy: 0.9929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ed084f63a00>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d96dbf01",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "model.save('LeNet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb490574",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Évaluer les performances du modèle (classification_report) sur le jeu de test de MNIST. Vous devriez obtenir un score proche de 99% pour ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4f56eb9-09fe-4ea3-8301-0bcf629b8fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       980\n",
      "           1       1.00      0.99      0.99      1135\n",
      "           2       0.98      1.00      0.99      1032\n",
      "           3       0.98      1.00      0.99      1010\n",
      "           4       0.99      0.98      0.99       982\n",
      "           5       0.99      0.98      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       0.98      0.98      0.98       974\n",
      "           9       0.97      0.99      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convertir les probabilités en classes prédictes (en prenant la classe avec la probabilité maximale --> np.argmax)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convertir les étiquettes réelles en classes (en prenant l'index des classes)\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Générer le rapport de classification avec précision, rappel et F1-score\n",
    "report = classification_report(y_true, y_pred_classes)\n",
    "\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "date": 1725613532.7758572,
  "filename": "tpDeepLearning3.rst",
  "kernelspec": {
   "display_name": "jpn_florian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "title": "Travaux pratiques - Deep Learning avec Keras"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
