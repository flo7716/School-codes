{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Afficher les appareils disponibles\n",
        "print(\"GPU disponible :\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "xsRZ7Q69VWA9"
      },
      "id": "xsRZ7Q69VWA9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Téléchargement et extraction du jeu de données Cornell Movie Dialogs si nécessaire\n",
        "import os\n",
        "if(not os.path.exists(\"cornell movie-dialogs corpus\")):\n",
        "    !wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
        "    !unzip -o cornell_movie_dialogs_corpus.zip\n",
        "    !ls \"cornell movie-dialogs corpus\"\n",
        "else:\n",
        "    print(\"Le jeu de données est déjà téléchargé.\")"
      ],
      "metadata": {
        "id": "_C2EjIEQVXlP"
      },
      "id": "_C2EjIEQVXlP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Nettoyage rapide\n",
        "def clean_text(text):\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r\"[^a-zA-Z0-9.!?']\", \" \", text)\n",
        "    return \" \".join(text.split())\n",
        "\n",
        "# Chargement et création des paires (exemple simplifié)\n",
        "lines = open(\"movie_lines.txt\", encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "pairs = [(lines[i], lines[i+1]) for i in range(0, len(lines)-1, 2)]  # Paires adjacentes\n",
        "cleaned_pairs = [(clean_text(q), clean_text(a)) for q, a in pairs[:50000]]  # Limite à 50k\n",
        "\n",
        "# Tokenisation\n",
        "tokenizer = Tokenizer(num_words=8000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts([q for q, a in cleaned_pairs] + [a for q, a in cleaned_pairs])\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Séquences\n",
        "MAX_LEN = 15  # Réduit pour vitesse\n",
        "input_seqs = pad_sequences(tokenizer.texts_to_sequences([q for q, a in cleaned_pairs]), maxlen=MAX_LEN)\n",
        "target_seqs = pad_sequences(tokenizer.texts_to_sequences([a for q, a in cleaned_pairs]), maxlen=MAX_LEN)"
      ],
      "metadata": {
        "id": "ixJ8kTDMU_Ou"
      },
      "id": "ixJ8kTDMU_Ou",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "\n",
        "# Encodeur\n",
        "encoder_inputs = Input(shape=(MAX_LEN,))\n",
        "encoder_embed = Embedding(VOCAB_SIZE, 128)(encoder_inputs)\n",
        "_, state_h, state_c = LSTM(128, return_state=True)(encoder_embed)  # Unidirectionnel pour vitesse\n",
        "\n",
        "# Décodeur\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embed = Embedding(VOCAB_SIZE, 128)(decoder_inputs)\n",
        "decoder_outputs = LSTM(128, return_sequences=True)(decoder_embed, initial_state=[state_h, state_c])\n",
        "outputs = Dense(VOCAB_SIZE, activation='softmax')(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "8gQrDV_uVBRB"
      },
      "id": "8gQrDV_uVBRB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Préparation des données\n",
        "decoder_input_data = target_seqs[:, :-1]\n",
        "decoder_output_data = target_seqs[:, 1:]\n",
        "\n",
        "# Entraînement express\n",
        "model.fit(\n",
        "    [input_seqs, decoder_input_data],\n",
        "    np.expand_dims(decoder_output_data, -1),\n",
        "    batch_size=256,  # Batch large pour T4\n",
        "    epochs=10,\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "2mVnjiauVERt"
      },
      "id": "2mVnjiauVERt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(text, max_len=15):\n",
        "    text_seq = pad_sequences(tokenizer.texts_to_sequences([clean_text(text)]), maxlen=MAX_LEN)\n",
        "    states = model.layers[2].predict(text_seq)  # Récupère les états\n",
        "\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = tokenizer.word_index['<OOV>']  # Token de départ\n",
        "\n",
        "    response = []\n",
        "    for _ in range(max_len):\n",
        "        output, h, c = model.layers[4](target_seq, initial_state=states)\n",
        "        next_token = np.argmax(output[0, -1, :])\n",
        "        response.append(tokenizer.index_word.get(next_token, ''))\n",
        "        target_seq = np.array([[next_token]])\n",
        "        states = [h, c]\n",
        "\n",
        "    return ' '.join(response)\n",
        "\n",
        "# Test\n",
        "print(generate_response(\"Hello how are you?\"))"
      ],
      "metadata": {
        "id": "hAKwyfndVHoS"
      },
      "id": "hAKwyfndVHoS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xL-LBW9dVLQW"
      },
      "id": "xL-LBW9dVLQW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}