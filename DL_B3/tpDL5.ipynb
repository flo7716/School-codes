{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "2b8f1920",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-04-07 21:17:51--  https://github.com/flo7716/School-codes/blob/main/DL_B3/fleurs_mal.txt\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘fleurs_mal.txt.2’\n",
            "\n",
            "fleurs_mal.txt.2        [   <=>              ] 779.97K  1.36MB/s    in 0.6s    \n",
            "\n",
            "2025-04-07 21:17:52 (1.36 MB/s) - ‘fleurs_mal.txt.2’ saved [798693]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/flo7716/School-codes/blob/main/DL_B3/fleurs_mal.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7d3a3d0",
      "metadata": {
        "id": "e7d3a3d0"
      },
      "source": [
        "\n",
        "<a id='chap-tpdeeplearning5'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "289ced02-72b3-45c8-a60b-1d789224d1b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "289ced02-72b3-45c8-a60b-1d789224d1b1",
        "outputId": "2cbdc44b-0876-417f-a06f-ae7564539656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.test.is_built_with_cuda())  # Should return True\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "715887eb",
      "metadata": {
        "id": "715887eb"
      },
      "source": [
        "# Travaux pratiques - RNN pour la génération de texte\n",
        "\n",
        "L’objectif de cette séance de travaux pratiques est d’illustrer la mise\n",
        "en application des réseaux de neurones récurrents sur des données\n",
        "séquentielles. En particulier, nous allons nous intéresser aux modèles\n",
        "auto-régressifs pour la génération de texte."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d6c4253",
      "metadata": {
        "id": "6d6c4253"
      },
      "source": [
        "## Génération de poésie\n",
        "\n",
        "Une première application des réseaux de neurones récurents est la\n",
        "génération de texte. Pour démarrer, nous allons extraire les textes d’un\n",
        "recueil de poésies, « Les fleurs du mal » (1857) de l’écrivain [Charles\n",
        "Baudelaire](https://fr.wikipedia.org/wiki/Charles_Baudelaire)\n",
        "(1821-1867). Cet ensemble de textes va constituer notre corpus\n",
        "d’entraînement."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6964c3e2",
      "metadata": {
        "id": "6964c3e2"
      },
      "source": [
        "Dans notre application, nous nous intéressons à la génération de texte\n",
        "au travers de la *prédiction du mot suivant*. En considérant un texte\n",
        "comme une suite de mots $ (x_1, x_2, ..., x_m) $, nous allons\n",
        "entraîner un réseau de neurones récurrent de sorte à prédire le bon mot\n",
        "$ x_n $ à partir des mots $ (x_1, x_2, ..., x_{n-1}) $ qui le\n",
        "précèdent dans une phrase."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d25a78fa",
      "metadata": {
        "id": "d25a78fa"
      },
      "source": [
        "### Création du jeu de données d’entraînement\n",
        "\n",
        "Le code ci-dessous va nous servir à générer les données et les\n",
        "étiquettes correspondantes. On va commencer par parser le ficher\n",
        "d’entrée pour récupérer le texte et effectuer quelques pré-traitements\n",
        "simples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "22bdc95e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "hide-output": false,
        "id": "22bdc95e",
        "outputId": "131291cf-147b-4e6a-c4f5-9206c7a0bf74"
      },
      "outputs": [],
      "source": [
        "# Lire le fichier texte et ajouter toutes les lignes dans une liste\n",
        "with open(\"fleurs_mal.txt\", 'r' , encoding = 'utf8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for idx, line in enumerate(lines):\n",
        "    if \"Charles Baudelaire avait un ami\" in line:\n",
        "        first_line = idx\n",
        "    if \"End of the Project Gutenberg EBook of Les Fleurs du Mal, by Charles Baudelaire\" in line:\n",
        "        last_line = idx\n",
        "\n",
        "lines = lines[first_line:last_line]\n",
        "lines = [l.lower().strip().replace('_', '') for l in lines if len(l) > 1]\n",
        "text = \" \".join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "4bb5691f",
      "metadata": {
        "hide-output": false,
        "id": "4bb5691f"
      },
      "outputs": [],
      "source": [
        "characters = sorted(set(text))\n",
        "n_characters = len(characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "f4ed00ea-deb0-4f1f-a270-385be99fc3cf",
      "metadata": {
        "id": "f4ed00ea-deb0-4f1f-a270-385be99fc3cf",
        "outputId": "7e2ec736-71b6-4c8f-c4a2-6b48c622f7b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"charles baudelaire avait un ami, auguste poulet-malassis, ancien élève de l'école des chartes, qui s'était fait éditeur par goût pour les raffinements typographiques et pour la littérature qu'il jugeait en érudit et en artiste beaucoup plus qu'en commerçant;\""
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text[:258]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33538e9c",
      "metadata": {
        "id": "33538e9c"
      },
      "source": [
        "### Question\n",
        "\n",
        "Que contient la variable `characters` ? Que représente\n",
        "`n_characters` ? La documentation des\n",
        "[Set](https://docs.python.org/fr/3/tutorial/datastructures.html#sets)\n",
        "en Python peut vous aider.\n",
        "\n",
        "Dans la suite de ce TP, nous allons considérer le texte comme une suite\n",
        "de caractères. Nous n’allons donc pas raisonner au niveau du mot mais au\n",
        "niveau du symbole. Chaque caractère du texte d’entrée sera représenté en\n",
        "entrée du réseau de neurones par un encodage *one-hot* sur le\n",
        "dictionnaire de symboles. Autrement dit, pour un dictionnaire simplifié\n",
        "(” “, `a`, `b`, `c`, `d`), la lettre `a` serait représentée\n",
        "par le vecteur $ (0, 1, 0, 0, 0, 0) $ tandis que l’espace “ “\n",
        "serait représenté par le vecteur $ (1, 0, 0, 0, 0) $.\n",
        "\n",
        "Nous allons désormais entraîner un réseau de neurones récurrent.\n",
        "Celui-ci va recevoir en entrée une séquence de `SEQLEN` caractères.\n",
        "Son objectif sera de prédire en sortie le caractère suivant dans le\n",
        "corpus. Par exemple, pour la phrase :\n",
        "\n",
        "> Le vélo est rouge.\n",
        "\n",
        "\n",
        "le modèle devra prédire `l` à partir de la séquence `Le vé`, puis\n",
        "`o` à partir de la séquence `Le vél`, et ainsi de suite. Il s’agit\n",
        "donc d’un problème de classification à `n_characters` classes\n",
        "différentes (une classe par symbole).\n",
        "\n",
        "L’étiquette de classe est obtenue automatiquement à partir du corpus.\n",
        "Comme il n’y a eu aucune annotation manuelle du jeu de données, cet\n",
        "objectif de prédiction du caractère suivant représente un problème\n",
        "d’apprentissage dit *auto-supervisé* (ou *self-supervised*). La\n",
        "supervision est construite artificiellement à partir des données elles\n",
        "mêmes.\n",
        "\n",
        "Les données d’entraînement consistent donc en l’ensemble des séquences\n",
        "de caractères du corpus dont la taille est inférieure à `SEQLEN`.\n",
        "L’étiquette de la classe cible correspondante est celle de l’indice du\n",
        "prochain caractère à prédire, c’est-à-dire le caractère suivant dans le\n",
        "corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "be745872",
      "metadata": {
        "hide-output": false,
        "id": "be745872",
        "outputId": "fc5d922b-a222-4394-e8f5-07a5ecbc42fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Il y a 146120 séquences de 10 caractères dans le corpus d'entraînement.\n"
          ]
        }
      ],
      "source": [
        "# SEQLEN représente la taille de la séquence de lettres à passer en entrée\n",
        "SEQLEN = 10\n",
        "step = 1\n",
        "input_characters, labels = [], []\n",
        "# On parcourt le corpus de texte avec une fenêtre glissante\n",
        "for i in range(0, len(text) - SEQLEN, step):\n",
        "    input_characters.append(text[i:i + SEQLEN])\n",
        "    labels.append(text[i + SEQLEN])\n",
        "\n",
        "print(f\"Il y a {len(input_characters)} séquences de {SEQLEN} caractères dans le corpus d'entraînement.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "832d61e1-c8c0-4ee4-b83e-3908d091886e",
      "metadata": {
        "id": "832d61e1-c8c0-4ee4-b83e-3908d091886e",
        "outputId": "d2f278ed-ecea-445c-baf5-8189bef7388d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('charles ba', 'u')"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_characters[0], labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4be16ebe",
      "metadata": {
        "id": "4be16ebe"
      },
      "source": [
        "### Question\n",
        "\n",
        "Afficher une séquence de `SEQLEN` caractères et l’étiquette de classe\n",
        "correspondante, c’est-à-dire le caractère suivant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "6a0fd6d7-c0f5-453e-a614-8832c4610b81",
      "metadata": {
        "id": "6a0fd6d7-c0f5-453e-a614-8832c4610b81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Il y a 59 caractères uniques dans le corpus d'entraînement.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Il y a {n_characters} caractères uniques dans le corpus d'entraînement.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beaea871-ecce-46aa-8099-55d517e04005",
      "metadata": {
        "id": "beaea871-ecce-46aa-8099-55d517e04005"
      },
      "source": [
        "Nous pouvons maintenant vectoriser les données d’entraînement en\n",
        "utilisant le dictionnaire et un encodage *one-hot* pour chaque caractère\n",
        ":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "19182fe9",
      "metadata": {
        "hide-output": false,
        "id": "19182fe9"
      },
      "outputs": [],
      "source": [
        "# Encodage caractère -> indice du dictionaire\n",
        "char2index = dict((c, i) for i, c in enumerate(characters))\n",
        "# Encodage de l'indice vers le caractère (utilisé pour décoder les prédictions du modèle)\n",
        "index2char = dict((i, c) for i, c in enumerate(characters)) # mapping index -> char in dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ded531f",
      "metadata": {
        "id": "5ded531f"
      },
      "source": [
        "Chaque séquence d’entraînement est donc représentée par une matrice de\n",
        "taille $ SEQLEN \\times m $, correspondant à une longueur de\n",
        "`SEQLEN` caractères, chaque caractère étant encodé par un vecteur\n",
        "binaire correspondant à un encodage *one-hot*. $ m $ représente la\n",
        "taille du dictionnaire, c’est-à-dire le nombre de symboles uniques dans\n",
        "le corpus.\n",
        "\n",
        "- L’ensemble des données d’entraînement `X` seront donc constituées\n",
        "  par un tenseur de taille $ N \\times SEQLEN \\times m $ où $ N $\n",
        "  est le nombre de séquences de `SEQLEN` caractères dans le corpus.  \n",
        "- L’ensemble des labels d’entraînement `y` seront représentées par un\n",
        "  tenseur de $ N \\times m $, où la sortie pour chaque\n",
        "  exemple correspond à l’indice dans le dictionnaire du caractère\n",
        "  suivant la séquence  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60d5bc90",
      "metadata": {
        "id": "60d5bc90"
      },
      "source": [
        "### Question\n",
        "\n",
        "Compléter le code ci-dessous afin de créer les tenseurs `X` et `y`\n",
        "contenant les données d’entraînement (séquences de caractères dans `X`\n",
        "et étiquettes de classe dans `y`. Vous pourrez notamment utiliser à\n",
        "bon escient le dictionnaire `char2index` qui permet de transformer un\n",
        "caractère en son indice entier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "1a9fae51",
      "metadata": {
        "hide-output": false,
        "id": "1a9fae51"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X = np.zeros((len(input_characters), SEQLEN, n_characters), dtype=bool)\n",
        "y = np.zeros((len(input_characters), n_characters), dtype=bool)\n",
        "\n",
        "for idx_seq, sequence in enumerate(input_characters):\n",
        "    # À compléter\n",
        "    # Remplissage des tenseurs X et y\n",
        "    for idx_char, char in enumerate(sequence):\n",
        "        # Encodage one-hot dans X\n",
        "        X[idx_seq, idx_char, char2index[char]] = 1\n",
        "\n",
        "    next_char = labels[idx_seq]  # Récupérer le caractère cible\n",
        "    # Encodage one-hot dans y\n",
        "    y[idx_seq, char2index[next_char]] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c81cf12",
      "metadata": {
        "id": "7c81cf12"
      },
      "source": [
        "Comme à l’accoutumée, nous allons séparer le jeu de données en deux : un\n",
        "ensemble d’apprentissage et un ensemble de validation. Le jeu de\n",
        "validation nous permettra notamment d’évaluer les performances du modèle\n",
        "et d’éviter le sur-apprentissage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "3f6722b2",
      "metadata": {
        "hide-output": false,
        "id": "3f6722b2",
        "outputId": "a811f243-2029-48d3-de90-b6f6447814f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(131508, 59)"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 90% des données en apprentissage, 10% en validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28f7a96",
      "metadata": {
        "id": "d28f7a96"
      },
      "source": [
        "### Apprentissage d’un modèle auto-supervisé pour la génération de texte\n",
        "\n",
        "Maintenant que les données ont été formatées, nous pouvons commencer à\n",
        "définir le modèle que nous allons utiliser. Nous allons l’implémenter\n",
        "sous la forme d’un modèle Keras séquentiel\n",
        "([Sequential](https://keras.io/api/models/sequential/))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "20c8f992",
      "metadata": {
        "hide-output": false,
        "id": "20c8f992"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fed800f1",
      "metadata": {
        "id": "fed800f1"
      },
      "source": [
        "Pour l’instant, ce modèle est vide. Nous allons lui ajouter une couche\n",
        "récurrente avec un modèle de type `SimpleRNN` (la cellule récurrente\n",
        "la plus simple) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "59262127",
      "metadata": {
        "hide-output": false,
        "id": "59262127"
      },
      "outputs": [],
      "source": [
        "h_size = 59\n",
        "model.add(SimpleRNN(h_size, return_sequences=False, unroll=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c7cd80f",
      "metadata": {
        "id": "4c7cd80f"
      },
      "source": [
        "### Question\n",
        "\n",
        "À l’aide de la documentation de\n",
        "[SimpleRNN](https://keras.io/api/layers/recurrent_layers/simple_rnn/)\n",
        "dans Keras, expliquer à quoi correspondent les paramètres\n",
        "`h_size = 128` et `return_sequences=False`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8b79284",
      "metadata": {
        "id": "e8b79284"
      },
      "source": [
        "### Note\n",
        "\n",
        "L’argument optionnel `unroll=True` permet simplement\n",
        "d’accélérer les calculs en « déroulant » le réseau récurrent plutôt que\n",
        "d’utiliser une boucle `for` en interne.\n",
        "\n",
        "Pour terminer notre modèle, nous ajoutons enfin une couche entièrement\n",
        "connectée suivie d’une fonction `softmax` qui effectuera la\n",
        "classification du caractère suivant la séquence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "cc8c331b",
      "metadata": {
        "hide-output": false,
        "id": "cc8c331b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Activation\n",
        "\n",
        "model.add(Dense(h_size))\n",
        "model.add(Activation(\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "632e513c",
      "metadata": {
        "id": "632e513c"
      },
      "source": [
        "Empiriquement, il a été constaté que l’optimisation des réseaux\n",
        "récurrents est plus rapide et la convergence plus robuste lorsque l’on\n",
        "utilise des méthodes de descente de gradient à pas adaptatif, telles que\n",
        "`RMSprop` [[TH12]](#tieleman2012)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "d4605f8c",
      "metadata": {
        "hide-output": false,
        "id": "d4605f8c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "learning_rate = 0.001\n",
        "optim = RMSprop(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "213184c5",
      "metadata": {
        "id": "213184c5"
      },
      "source": [
        "Nous pouvons donc compiler le modèle et utiliser la méthode\n",
        "`summary()` de Keras pour visualiser le nombre de paramètres du\n",
        "réseaux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "91ed3666",
      "metadata": {
        "hide-output": false,
        "id": "91ed3666",
        "outputId": "d9bece0e-8d73-48aa-aff3-dfddb5ca2e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_11 (SimpleRNN)   (None, 59)                7021      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 59)                3540      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 59)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10561 (41.25 KB)\n",
            "Trainable params: 10561 (41.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build the model by specifying the input shape\n",
        "model.build(input_shape=(None, SEQLEN, n_characters))\n",
        "# Compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optim, metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e16858eb",
      "metadata": {
        "id": "e16858eb"
      },
      "source": [
        "L’entraînement s’effectue de la manière habituelle à l’aide de la\n",
        "méthode `fit()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "4847b3b3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((131508, 10, 59), (131508, 59), (14612, 10, 59), (14612, 59))"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "32a17db0",
      "metadata": {
        "hide-output": false,
        "id": "32a17db0",
        "outputId": "11983267-8807-4e2d-c541-4a231c952c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 2.5302 - accuracy: 0.2805\n",
            "Epoch 2/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 2.2086 - accuracy: 0.3415\n",
            "Epoch 3/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 2.1313 - accuracy: 0.3601\n",
            "Epoch 4/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 2.0828 - accuracy: 0.3719\n",
            "Epoch 5/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 2.0448 - accuracy: 0.3816\n",
            "Epoch 6/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 2.0140 - accuracy: 0.3904\n",
            "Epoch 7/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.9871 - accuracy: 0.3970\n",
            "Epoch 8/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.9647 - accuracy: 0.4034\n",
            "Epoch 9/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.9447 - accuracy: 0.4093\n",
            "Epoch 10/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.9273 - accuracy: 0.4128\n",
            "Epoch 11/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.9116 - accuracy: 0.4166\n",
            "Epoch 12/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8978 - accuracy: 0.4218\n",
            "Epoch 13/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8852 - accuracy: 0.4248\n",
            "Epoch 14/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8738 - accuracy: 0.4282\n",
            "Epoch 15/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8630 - accuracy: 0.4312\n",
            "Epoch 16/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8535 - accuracy: 0.4330\n",
            "Epoch 17/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8448 - accuracy: 0.4367\n",
            "Epoch 18/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8362 - accuracy: 0.4397\n",
            "Epoch 19/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8287 - accuracy: 0.4421\n",
            "Epoch 20/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8213 - accuracy: 0.4437\n",
            "Epoch 21/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8148 - accuracy: 0.4454\n",
            "Epoch 22/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8078 - accuracy: 0.4471\n",
            "Epoch 23/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.8029 - accuracy: 0.4486\n",
            "Epoch 24/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7977 - accuracy: 0.4511\n",
            "Epoch 25/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7920 - accuracy: 0.4521\n",
            "Epoch 26/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7874 - accuracy: 0.4538\n",
            "Epoch 27/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7826 - accuracy: 0.4542\n",
            "Epoch 28/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7782 - accuracy: 0.4556\n",
            "Epoch 29/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7740 - accuracy: 0.4579\n",
            "Epoch 30/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7706 - accuracy: 0.4583\n",
            "Epoch 31/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7672 - accuracy: 0.4579\n",
            "Epoch 32/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7639 - accuracy: 0.4597\n",
            "Epoch 33/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7604 - accuracy: 0.4611\n",
            "Epoch 34/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7576 - accuracy: 0.4620\n",
            "Epoch 35/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7542 - accuracy: 0.4631\n",
            "Epoch 36/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7517 - accuracy: 0.4640\n",
            "Epoch 37/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7492 - accuracy: 0.4653\n",
            "Epoch 38/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7470 - accuracy: 0.4645\n",
            "Epoch 39/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7445 - accuracy: 0.4657\n",
            "Epoch 40/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7422 - accuracy: 0.4660\n",
            "Epoch 41/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7397 - accuracy: 0.4671\n",
            "Epoch 42/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7373 - accuracy: 0.4679\n",
            "Epoch 43/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7356 - accuracy: 0.4689\n",
            "Epoch 44/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7339 - accuracy: 0.4685\n",
            "Epoch 45/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7317 - accuracy: 0.4702\n",
            "Epoch 46/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7299 - accuracy: 0.4697\n",
            "Epoch 47/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7284 - accuracy: 0.4707\n",
            "Epoch 48/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7266 - accuracy: 0.4718\n",
            "Epoch 49/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7250 - accuracy: 0.4714\n",
            "Epoch 50/50\n",
            "1028/1028 [==============================] - 3s 3ms/step - loss: 1.7235 - accuracy: 0.4717\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x70c954709e20>"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 128\n",
        "num_epochs = 50\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa971e95",
      "metadata": {
        "id": "aa971e95"
      },
      "source": [
        "Nous pouvons utiliser la méthode `.evaluate()` pour calculer\n",
        "automatiquement les métriques spécifiées à la compilation du modèle sur\n",
        "un jeu de données. Calculons par exemple les scores de taux de bonne\n",
        "classification (*accuracy*) sur le jeu d’apprentissage et sur le jeu de\n",
        "test :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "f6a22bc4",
      "metadata": {
        "hide-output": false,
        "id": "f6a22bc4",
        "outputId": "94a7ff55-23ef-4a6c-fbb5-446251379b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performances (apprentissage, accuracy) = 47.32\n",
            "Performances (validation, accuracy) = 45.78\n"
          ]
        }
      ],
      "source": [
        "scores_train = model.evaluate(X_train, y_train, verbose=0)\n",
        "scores_test = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Performances (apprentissage, {model.metrics_names[1]}) = {scores_train[1]*100:.2f}\")\n",
        "print(f\"Performances (validation, {model.metrics_names[1]}) = {scores_test[1]*100:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "896782d8",
      "metadata": {
        "id": "896782d8"
      },
      "source": [
        "*Note*: Il est possible de sauvegarder les paramètres du modèle appris à\n",
        "l’aide de la méthode `.save()`. Cela permet notamment de réutiliser le\n",
        "modèle plus tard, sans avoir à l’entraîner de nouveau."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "dbcc0d7c",
      "metadata": {
        "hide-output": false,
        "id": "dbcc0d7c"
      },
      "outputs": [],
      "source": [
        "model_name = f\"SimpleRNN_{h_size}_{num_epochs}epochs.keras\"\n",
        "model.save(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a6118bf",
      "metadata": {
        "id": "1a6118bf"
      },
      "source": [
        "### Analyse de l’apprentissage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c3d54dc",
      "metadata": {
        "id": "0c3d54dc"
      },
      "source": [
        "### Question\n",
        "\n",
        "Quels taux de classification obtient-on en apprentissage ? En validation\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37911876",
      "metadata": {
        "id": "37911876"
      },
      "source": [
        "### Question\n",
        "\n",
        "En quoi le problème est-il différents des problèmes de classification\n",
        "abordés jusqu’ici ? Par exemple, faire une recherche de la séquence\n",
        "d’entrée « la mort de », et analyser les labels cibles présents dans le\n",
        "corpus d’apprentissage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b71f1c45",
      "metadata": {
        "id": "b71f1c45"
      },
      "source": [
        "### Génération de texte à partir du modèle appris\n",
        "\n",
        "Nous pouvons désormais nous servir du modèle entraîné pour générer du\n",
        "texte qui va « imiter » le style du corpus de poésie initial (*Les\n",
        "Fleurs du mal*). Si nécessaire, commençons par charger les paramètres du\n",
        "réseau récurrent précédemment entraîné à l’aide de la fonction\n",
        "`loadModel` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "14cb02d4",
      "metadata": {
        "hide-output": false,
        "id": "14cb02d4",
        "outputId": "93eaa28f-c358-4aeb-924b-b7e41efe8837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_11 (SimpleRNN)   (None, 59)                7021      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 59)                3540      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 59)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10561 (41.25 KB)\n",
            "Trainable params: 10561 (41.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(model_name)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "621edd35",
      "metadata": {
        "id": "621edd35"
      },
      "source": [
        "Comme le modèle a été entraîné pour prédire le caractère suivant à\n",
        "partir d’une séquence de `SEQLEN` caractères précédent, nous devons\n",
        "l’initialiser avec une chaîne de caractères de départ. Le modèle pourra\n",
        "ensuite générer du texte en prédisant les caractères suivants un par un.\n",
        "\n",
        "Reprenons un texte initial issu de notre corpus d’entraînement :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "908aa8d2-3368-44ca-a57c-fa40f667e264",
      "metadata": {
        "id": "908aa8d2-3368-44ca-a57c-fa40f667e264",
        "outputId": "654284a2-04a7-4509-814e-002074b31b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La séquence n°10 est : ' qu'une cl'\n"
          ]
        }
      ],
      "source": [
        "idx= 10\n",
        "# index2char permet de repasser de l'encodage one-hot au caractère du dictionnaire\n",
        "initial_characters = [index2char[np.argmax(c)] for c in X_train[idx]]\n",
        "initial_text = \"\".join(initial_characters)\n",
        "print(f\"La séquence n°{idx} est : '{initial_text}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0fcb3b5",
      "metadata": {
        "id": "d0fcb3b5"
      },
      "source": [
        "Nous pouvons maintenant extraire la représentation en encodage *one-hot*\n",
        "de ce texte, que nous passerons ensuite dans le réseau entraîné pour\n",
        "obtenir la prédiction du caractère suivant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "e3a73732",
      "metadata": {
        "hide-output": false,
        "id": "e3a73732",
        "outputId": "7dcb4281-d8da-4870-b042-ded86f7cb539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n",
            "[[2.7085681e-04 1.3478141e-05 2.5185312e-03 3.2861404e-05 4.3679589e-05\n",
            "  6.7043140e-05 1.4864804e-05 7.9784288e-05 1.3624537e-05 2.2148219e-05\n",
            "  1.4267722e-05 2.2317694e-05 1.7991355e-05 3.0723637e-05 1.5316844e-05\n",
            "  2.3664103e-05 1.5681208e-05 7.9908561e-05 4.1811535e-01 1.4498232e-04\n",
            "  3.3417883e-04 2.9774907e-05 2.7154067e-01 1.5574973e-04 7.2341616e-05\n",
            "  3.3703807e-04 3.7491906e-02 1.0971951e-04 1.9330128e-05 3.4377684e-03\n",
            "  8.0702396e-04 2.1660653e-05 2.0787546e-01 2.0422128e-03 1.7956585e-04\n",
            "  6.6160275e-05 3.7163907e-05 1.2088626e-04 9.2207938e-03 6.5577674e-06\n",
            "  2.5785388e-05 1.1815487e-06 3.6195945e-04 4.8781089e-06 1.3710106e-05\n",
            "  4.1847688e-06 3.6174909e-04 5.9232046e-03 7.0270221e-06 2.5081465e-03\n",
            "  3.4678955e-02 3.0499100e-04 5.0131126e-05 2.2016009e-04 1.1638280e-05\n",
            "  2.1730608e-05 2.4951557e-06 2.1087732e-05 1.3869984e-05]]\n"
          ]
        }
      ],
      "source": [
        "test_sequence = np.zeros((1, SEQLEN, n_characters), dtype=bool)\n",
        "test_sequence[0] = X_train[idx]\n",
        "prediction = model.predict(test_sequence)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968ee9b0",
      "metadata": {
        "id": "968ee9b0"
      },
      "source": [
        "### Question\n",
        "\n",
        "À l’aide du dictionnaire `index2char`, déterminer quel\n",
        "est le prochain caractère prédit par le modèle.\n",
        "\n",
        "Au lieu de prédire systématiquement le symbole dont la probabilité est\n",
        "maximale, nous pouvons ajouter du non-déterministe (et donc de\n",
        "l’aléatoire) dans la génération de texte en échantillonnant selon la\n",
        "distribution de probabilités en sortie du softmax. Autrement dit, plus\n",
        "un symbole aura une forte activation après le softmax, plus il aura de\n",
        "chances d’être tiré.\n",
        "\n",
        "Pour contrôler à quel point cet échantillonnage sera non-déterministe,\n",
        "nous allons introduire un nouveau paramètre permettant de contrôler la\n",
        "forme de la distribution. En notant $ T $ ce nouveau paramètre, nous\n",
        "allons altérer les probabilités de sortie en les remplaçant par la\n",
        "formule suivante :\n",
        "\n",
        "$$\n",
        "z_{i}^N  = \\frac{z_{i}^{\\frac{1}{T}}}{\\sum\\limits_{j=1}^C z_{j}^{\\frac{1}{T}} }\n",
        "$$\n",
        "\n",
        "$ T $ est un paramètre appelé *température*. Si $ T=1 $, alors\n",
        "il s’agit du softmax habituel.\n",
        "\n",
        "La figure ci-dessous montre l’impact sur la distribution de cette\n",
        "renormalisation :\n",
        "\n",
        "Nous pourrons par la suite utiliser la fonction ci-dessous qui tire\n",
        "aléatoirement un symbole en échantillonnant selon la distribution,\n",
        "éventuellement modifiée par la température."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "id": "bddb3dca",
      "metadata": {
        "hide-output": false,
        "id": "bddb3dca"
      },
      "outputs": [],
      "source": [
        "def sample(probabilities, temperature=1.0):\n",
        "    probabilities = np.asarray(probabilities).astype('float64')\n",
        "    # Modifie la distribution selon la valeur de la température\n",
        "    probabilities = pow(probabilities, 1.0/temperature)\n",
        "    probabilities /= np.sum(probabilities)\n",
        "    # Tire des variables aléatoires selon la distribution multinomiale transformée\n",
        "    random_values = np.random.multinomial(1, probabilities, 1)\n",
        "    # Renvoie le symbole échantillonné\n",
        "    return np.argmax(random_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a43b4a5f",
      "metadata": {
        "id": "a43b4a5f"
      },
      "source": [
        "### Question\n",
        "\n",
        "Comment est-ce que la température modifie la distribution\n",
        "lorsqu’elle augmente ($ T \\rightarrow +\\infty $) ou\n",
        "diminue ($ T \\rightarrow 0 $) ?\n",
        "Comment cela va-t-il influer sur l’échantillonnage du caractère suivant ?\n",
        "\n",
        "Pour terminer, nous pouvons mettre en place la génération de texte à\n",
        "partir d’une séquence de `SEQLEN` caractères initiaux. Pour ce faire,\n",
        "nous allons créer une boucle qui :\n",
        "\n",
        "1. extraie les `SEQLEN` derniers caractères du texte généré  \n",
        "1. calcule les probabilités après softmax du réseau (méthode\n",
        "  `.predict()`)  \n",
        "1. échantillonne un caractère dans ces probabilités (fonction\n",
        "  `sample()`)  \n",
        "1. ajoute ce caractère au texte généré  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3257eab8",
      "metadata": {
        "id": "3257eab8"
      },
      "source": [
        "### Question\n",
        "\n",
        "Compléter le code de génération de texte ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "e52a386e",
      "metadata": {
        "hide-output": false,
        "id": "e52a386e",
        "outputId": "7cca48a0-0fe9-4c3e-87a8-0f8488f04e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texte généré :\n",
            " qu'une cleubles qui nousfurs incumbe: j'est les choondai tout tes vidin comme des ne fourde mon coeurs ces leinules que cette les ablemes crésus gréter ayprés pas comme un rigner et forteur et décîme au gormin\n"
          ]
        }
      ],
      "source": [
        "# Longueur du texte à générer (en caractères)\n",
        "text_length = 200\n",
        "# Température\n",
        "temperature  = 0.9\n",
        "\n",
        "\n",
        "generated_text = initial_text\n",
        "network_input = test_sequence\n",
        "\n",
        "for i in range(text_length):\n",
        "    last_characters = generated_text[-SEQLEN:]  # Séquence d'entrée\n",
        "    # Compléter le code\n",
        "    # Transformer la séquence en encodage one-hot\n",
        "    x_pred = np.zeros((1, SEQLEN, n_characters), dtype=bool)\n",
        "    for t, char in enumerate(last_characters):\n",
        "        x_pred[0, t, char2index[char]] = 1\n",
        "\n",
        "    # Prédire la distribution des probabilités des prochains caractères\n",
        "    predictions = model.predict(x_pred, verbose=0)[0]\n",
        "\n",
        "    # Échantillonnage du prochain caractère à l'aide de la fonction sample\n",
        "    next_index = sample(predictions, temperature)\n",
        "    next_char = index2char[next_index]\n",
        "\n",
        "    # Ajout du caractère généré au texte\n",
        "    generated_text += next_char\n",
        "\n",
        "    # Mise à jour de l'entrée pour la prochaine itération\n",
        "    network_input = list(network_input[1:]) + [next_char]\n",
        "\n",
        "\n",
        "print(\"Texte généré :\")\n",
        "print(generated_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39452d30",
      "metadata": {
        "id": "39452d30"
      },
      "source": [
        "### Question\n",
        "\n",
        "Évaluer l’impact du paramètre de température dans la génération,\n",
        "ainsi que le nombre d’époques dans l’apprentissage.\n",
        "Commenter les points forts et points faibles du générateur."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed4f3ab9",
      "metadata": {
        "id": "ed4f3ab9"
      },
      "source": [
        "## Pour aller plus loin\n",
        "\n",
        "Comment doit-on modifier le jeu de données ou modèle de RNN pour\n",
        "améliorer les performances du générateur ? Essayez notamment d’augmenter\n",
        "`SEQLEN`. Quel problème cela résout-il ? Un modèle avec plus de\n",
        "paramètres donne-t-il de meilleurs résultats ?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "date": 1725613532.8071067,
    "filename": "tpDeepLearning5.rst",
    "kernelspec": {
      "display_name": "jpn_florian",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "title": "Travaux pratiques - RNN pour la génération de texte"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
