{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Machine Learning \n",
    "# Florian André 3B IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset utilisé : Backpack Prediction Challenge trouvé sur Kaggle \n",
    "URL : https://www.kaggle.com/competitions/playground-series-s5e2/overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explication du dataset\n",
    "Ce dataset est composé de 4 fichiers \n",
    "- train.csv : notre dataset d'entraînement\n",
    "- train_extra.csv : dataset d'entraînement supplémentaire (avec erreurs)\n",
    "- test.csv : dataset pour tester notre modèle\n",
    "- sample_submission : dataset contenant l'id des sacs testés ainsi que leur prédiction de prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Liste des bibliothèques utilisées\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation et nettoyage des données\n",
    "\n",
    "Nous allons dans un premier temps importer les données d'entraînement de notre fichier train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id         Brand Material    Size  Compartments Laptop Compartment  \\\n",
      "0   0      Jansport  Leather  Medium           7.0                Yes   \n",
      "1   1      Jansport   Canvas   Small          10.0                Yes   \n",
      "2   2  Under Armour  Leather   Small           2.0                Yes   \n",
      "3   3          Nike    Nylon   Small           8.0                Yes   \n",
      "4   4        Adidas   Canvas  Medium           1.0                Yes   \n",
      "\n",
      "  Waterproof      Style  Color  Weight Capacity (kg)      Price  \n",
      "0         No       Tote  Black             11.611723  112.15875  \n",
      "1        Yes  Messenger  Green             27.078537   68.88056  \n",
      "2         No  Messenger    Red             16.643760   39.17320  \n",
      "3         No  Messenger  Green             12.937220   80.60793  \n",
      "4        Yes  Messenger  Green             17.749338   86.02312  \n",
      "(300000, 11)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/florian-andr/Downloads/playground-series-s5e2\"\n",
    "df_train = pd.read_csv(f\"{path}/train.csv\")\n",
    "print(df_train.head())\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procédons maintenant au nettoyage des données : en effet, certaines lignes comportent des valeurs nulles qu'il faut éliminer avant d'effectuer l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id         Brand Material    Size  Compartments Laptop Compartment  \\\n",
      "0   0      Jansport  Leather  Medium           7.0                Yes   \n",
      "1   1      Jansport   Canvas   Small          10.0                Yes   \n",
      "2   2  Under Armour  Leather   Small           2.0                Yes   \n",
      "3   3          Nike    Nylon   Small           8.0                Yes   \n",
      "4   4        Adidas   Canvas  Medium           1.0                Yes   \n",
      "\n",
      "  Waterproof      Style  Color  Weight Capacity (kg)      Price  \n",
      "0         No       Tote  Black             11.611723  112.15875  \n",
      "1        Yes  Messenger  Green             27.078537   68.88056  \n",
      "2         No  Messenger    Red             16.643760   39.17320  \n",
      "3         No  Messenger  Green             12.937220   80.60793  \n",
      "4        Yes  Messenger  Green             17.749338   86.02312  \n",
      "(246686, 11)\n"
     ]
    }
   ],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "print(df_train.head())\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous faut aussi éliminer les valeurs aberrantes sur \"Weight Capacity (kg)\" et \"Price\". On utilisera le z-score pour procéder à l'élimination de ces valeurs. \n",
    "Nous avons divisé le dataset en 2 quartiles (25% et 75%) sur la capacité de poids et le prix. Chaque valeur qui dépassera de 50% l'écart inter-quartile sera écartée\n",
    "du dataset d'entraînement final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234381, 11)\n"
     ]
    }
   ],
   "source": [
    "QW1 = df_train[\"Weight Capacity (kg)\"].quantile(0.25)\n",
    "QW3 = df_train[\"Weight Capacity (kg)\"].quantile(0.75)\n",
    "IQWR = QW3 - QW1\n",
    "\n",
    "QP1 = df_train[\"Price\"].quantile(0.25)\n",
    "QP3 = df_train[\"Price\"].quantile(0.75)\n",
    "IQPR = QP3 - QP1\n",
    "\n",
    "threshold = 0.5\n",
    "df_train = df_train[(df_train[\"Weight Capacity (kg)\"] > (QW1 - threshold * IQWR)) & (df_train[\"Weight Capacity (kg)\"] < (QW3 + threshold * IQWR))]\n",
    "df_train = df_train[(df_train[\"Price\"] > (QP1 - threshold * IQPR)) & (df_train[\"Price\"] < (QP3 + threshold * IQPR))]\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement des données (Data pre-processing)\n",
    "Maintenant que notre dataset d'entraînement a été nettoyé, il faut prétraiter nos données via le feature engineering. On va utiliser une Random Forest ainsi que la méthode Feature Importance afin de ne garder que les variables les plus pertinentes pour notre modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doit d'abord encoder les variables catégorielles de notre dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  Compartments  Weight Capacity (kg)      Price  Brand_numeric  \\\n",
      "0   0           7.0             11.611723  112.15875              0   \n",
      "1   1          10.0             27.078537   68.88056              0   \n",
      "2   2           2.0             16.643760   39.17320              1   \n",
      "3   3           8.0             12.937220   80.60793              2   \n",
      "4   4           1.0             17.749338   86.02312              3   \n",
      "\n",
      "   Material_numeric  Size_numeric  Laptop Compartment_numeric  \\\n",
      "0                 0             0                           0   \n",
      "1                 1             1                           0   \n",
      "2                 0             1                           0   \n",
      "3                 2             1                           0   \n",
      "4                 1             0                           0   \n",
      "\n",
      "   Waterproof_numeric  Style_numeric  Color_numeric  \n",
      "0                   0              0              0  \n",
      "1                   1              1              1  \n",
      "2                   0              1              2  \n",
      "3                   0              1              1  \n",
      "4                   1              1              1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train[\"Brand_numeric\"] = pd.factorize(df_train[\"Brand\"])[0]\n",
    "df_train[\"Material_numeric\"] = pd.factorize(df_train[\"Material\"])[0]\n",
    "df_train[\"Size_numeric\"] = pd.factorize(df_train[\"Size\"])[0]\n",
    "df_train[\"Laptop Compartment_numeric\"] = pd.factorize(df_train[\"Laptop Compartment\"])[0]\n",
    "df_train[\"Waterproof_numeric\"] = pd.factorize(df_train[\"Waterproof\"])[0]\n",
    "df_train[\"Style_numeric\"] = pd.factorize(df_train[\"Style\"])[0]\n",
    "df_train[\"Color_numeric\"] = pd.factorize(df_train[\"Color\"])[0]\n",
    "\n",
    "df_train.drop(columns=[\"Brand\", \"Material\", \"Size\", \"Laptop Compartment\", \"Waterproof\", \"Style\", \"Color\"], inplace=True)\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les variables encodées, il est possible d'utiliser RandomForest pour avoir la Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "X_train = df_train.drop(columns=[\"id\",\"Price\"])\n",
    "y_train = df_train[\"Price\"]\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = rf.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compartments</td>\n",
       "      <td>0.127694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weight Capacity (kg)</td>\n",
       "      <td>0.482544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brand_numeric</td>\n",
       "      <td>0.067224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Material_numeric</td>\n",
       "      <td>0.042666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Size_numeric</td>\n",
       "      <td>0.061745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Laptop Compartment_numeric</td>\n",
       "      <td>0.039072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Waterproof_numeric</td>\n",
       "      <td>0.036080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Style_numeric</td>\n",
       "      <td>0.061707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Color_numeric</td>\n",
       "      <td>0.081268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature  Importance\n",
       "0                Compartments    0.127694\n",
       "1        Weight Capacity (kg)    0.482544\n",
       "2               Brand_numeric    0.067224\n",
       "3            Material_numeric    0.042666\n",
       "4                Size_numeric    0.061745\n",
       "5  Laptop Compartment_numeric    0.039072\n",
       "6          Waterproof_numeric    0.036080\n",
       "7               Style_numeric    0.061707\n",
       "8               Color_numeric    0.081268"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_features = 6\n",
    "top_features = importance_df.head(top_n_features)['Feature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "une fois les features les plus importantes sélectionnées, il est possible d'entraîner notre modèle à l'aide d'un perceptron multi-couches (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(random_state=42)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "rgr = MLPRegressor(random_state=42, solver='adam')\n",
    "rgr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation du modèle\n",
    "Une fois le modèle entraîné, il ne nous reste plus qu'à l'évaluer sur le dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f\"{path}/test.csv\")\n",
    "X_test = df_test.drop([\"id\"], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jpn_florian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
