{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840f55de",
   "metadata": {},
   "source": [
    "\n",
    "<a id='chap-tpdeeplearning1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d6084",
   "metadata": {},
   "source": [
    "# Travaux pratiques - Premiers réseaux de neurones\n",
    "\n",
    "Au cours de cette séance de travaux pratiques, vous allez être amenés à implémenter vous-même l’apprentissage d’un réseau de neurones simple. Bien que de nombreuses bibliothèques existent pour automatiser cette tâche, il est très utile de se familiariser avec les concepts fondamentaux au moins une fois. Cela vous permettra d’avoir une meilleure compréhension des outils que nous utiliserons plus tard, comme Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79b434",
   "metadata": {},
   "source": [
    "## Jeu de données MNIST\n",
    "\n",
    "Lors de cette séance, nous allons utiliser la base de données MNIST, composée de 70 000 images de chiffres manuscrits en noir et blanc (60 000 pour l’entraînement et 10 000 pour le test). L’objectif est de développer un modèle capable d’identifier automatiquement le chiffre à partir de chaque image.\n",
    "\n",
    "Pour commencer, nous allons importer les données. Étant donné qu’il s’agit d’un jeu de données largement utilisé et standard, il est intégré dans plusieurs bibliothèques, comme Keras, ce qui nous permet de l’importer facilement en une seule ligne de code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b977c142-6bfc-4471-8e6b-481c2949a723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: keras in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (2.13.1)\n",
      "Collecting keras\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: numpy in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (1.24.3)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: scipy in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (1.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (1.69.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow keras numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9290b648-c045-4ca6-b8f7-df1acb7e5f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/florian-andr/anaconda3/envs/jpn_florian/bin/python\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import sys; print(sys.executable)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2b4807a-9c84-4f8c-8165-2fa4110239d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show numpy\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3220bff",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 exemples d'apprentissage\n",
      "10000 exemples de test\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# Import de MNIST depuis Keras\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# Transformation des images 28x28 en vecteur de dimension 784\n",
    "X_train = X_train.reshape(60000, 784).astype('float32')\n",
    "X_test = X_test.reshape(10000, 784).astype('float32')\n",
    "# Normalisation entre 0 et 1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Affichage du nombre de'exemples\n",
    "print(f\"{X_train.shape[0]} exemples d'apprentissage\")\n",
    "print(f\"{X_test.shape[0]} exemples de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb0017",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Afficher à l’aide de matplotlib les premières images du jeu d’apprentissage. La fonction `plt.imshow()` (cf. [sa documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html)) peut vous être utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccf7b9f9-9cdb-4ebe-85cf-84c1d78d16e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "n_images = 10\n",
    "for i in range(n_images):\n",
    "    plt.subplot(1, n_images, i+1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0f2f2",
   "metadata": {},
   "source": [
    "## Question :\n",
    "\n",
    "Quel est l’espace dans lequel se trouvent les images ? Quelle est sa dimension ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c82065f2-be15-4ec6-b8cd-b8cb01ab5898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c58781",
   "metadata": {},
   "source": [
    "## Régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b020534b",
   "metadata": {},
   "source": [
    "### Modèle de prédiction\n",
    "\n",
    "Nous allons implémenter un modèle de classification linéaire simple : la régression logistique. Concrètement, la régression logistique est équivalente à un réseau de neurones à une seule couche. Il s’agit d’une projection du vecteur d’entrée $ \\mathbf{x_i} $ par un vecteur de paramètres $ \\mathbf{w_{c}} $, plus un biais sclaaire $ b_c $, pour chaque classe.  Le schéma ci-dessous illustre le modèle de régression logistique avec un réseau de neurones.\n",
    "\n",
    "<img src=\"LR.png\" style=\"height:150px;\" align=\"center\">\n",
    "\n",
    "En l’occurrence, pour MNIST $ \\mathbf{x}_i $ est de dimension 784 et il y a dix chiffres possibles, donc 10 classes différentes. Dans notre cas, on considère que l’image d’entrée est représentée sous sa forme « aplatie », c’est-à-dire un vecteur (1, 784).\n",
    "\n",
    "Pour simplifier les notations, on regroupe l’ensemble des jeux de paramètres $ \\mathbf{w_{c}} $ pour les 10 classes possibles dans une unique matrice $ \\mathbf{W} $ de dimensions $ 784\\times 10 $. De la même façon, les biais sont regroupés dans un vecteur $ \\mathbf{b} $ de longueur 10. La sortie de la régression logistique est un vecteur contenant une activation pour chaque classe, c’est-à-dire $ \\mathbf{\\hat{s_i}} =\\mathbf{x_i}  \\mathbf{W}  + \\mathbf{b} $ de dimensions (1, 10).\n",
    "\n",
    "Afin de transformer les activations en de sortie en probabilités pour une distribution catégorielle, on ajoute une fonction d’activation de *softmax* sur $ \\mathbf{\\hat{y_i}} = \\sigma(\\mathbf{s_i}) $. Cela nous permet d’obtenir en sortie un vecteur de prédictions $ \\mathbf{\\hat{y_i}} $, de dimensions (1, 10),  qui représente la probabilité *a posteriori* $ p(\\mathbf{\\hat{y_i}} | \\mathbf{x_i}) $ pour chacune des 10 classes :\n",
    "\n",
    "\n",
    "<a id='equation-softmax'></a>\n",
    "$$\n",
    "p(\\hat{y}_{c,i} | \\mathbf{x_i}) ) = \\frac{e^{\\langle \\mathbf{x_i} ; \\mathbf{w_{c}}\\rangle + b_{c}}}{\\sum_{c'=1}^{10} e^{\\langle \\mathbf{x_i} ; \\mathbf{w_{c'}}\\rangle + b_{c'}}} \\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15508582",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Quel est le nombre de paramètres du modèle utilisé ? Justifier le calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec43ebb3-8de7-4183-875c-5e9223559cc6",
   "metadata": {},
   "source": [
    "\"784 * 10 + 10 = 7850 paramètres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16936d3e",
   "metadata": {},
   "source": [
    "### Formulation du problème d’apprentissage\n",
    "\n",
    "Pour entraîner le réseau de neurones, c’est-à-dire déterminer les valeurs optimales des paramètres $ \\mathbf{W} $ et $ \\mathbf{b} $, on va comparer pour chaque exemple d’apprentissage la sortie prédite $ \\mathbf{\\hat{y_i}} $ (équation [(1)](#equation-softmax)) pour l’image $ \\mathbf{x_i} $ à la sortie réelle $ \\mathbf{y_i^*} $ (vérité terrain issue de la supervision). Dans notre cas, on choisit d’encoder la catégorie de l’image $ \\mathbf{x_i} $ sous forme *one-hot*, c’est-à-dire :\n",
    "\n",
    "\n",
    "<a id='equation-one-hot'></a>\n",
    "$$\n",
    "y_{c,i}^* =\n",
    " \\begin{cases}\n",
    "   1 & \\text{si c correspond à l'indice de la classe de } \\mathbf{x_i}  \\\\\n",
    "   0 & \\text{sinon}\n",
    " \\end{cases} \\tag{2}\n",
    "$$\n",
    "\n",
    "Générons les étiquettes (*labels*) au format *one-hot* ([(2)](#equation-one-hot)) à l’aide de la fonction `to_categorical` (cf. [documentation de Keras](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b514892",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "n_classes = 10\n",
    "# Conversion des étiquettes (int) au format vectoriel one-hot\n",
    "Y_train = to_categorical(y_train, n_classes)\n",
    "Y_test = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5e911",
   "metadata": {},
   "source": [
    "L’erreur de prédiction sera définie à l’aide de l’entropie croisée (*cross-entropy*). Cette fonction de coût s’applique entre $ \\mathbf{\\hat{y_i}} $ et $ \\mathbf{y_i^*} $ par la formule:\n",
    "$ \\mathcal{L}(\\mathbf{\\hat{y_i}}, \\mathbf{y_i^*}) = -\\sum_{c=1}^{10} y_{c,i}^* \\log(\\hat{y}_{c,i}) = - \\log(\\hat{y}_{c^*,i}) $, où $ c^* $ correspond à l’indice de la classe donnée par la supervision pour l’image $ \\mathbf{x_i} $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b5186",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "L’entropie croisée correspond en réalité à la divergence de Kullback-Leiber pour des distributions catégorielles. La divergence KL est une mesure de dissimilarité entre distributions de probabilité. Autrement dit, l’erreur que l’on mesure vise à réduire l’écart entre la distribution réelle des catégories et la distribution prédite.\n",
    "\n",
    "La fonction de coût finale correspond à l’erreur d’apprentissage, c’est-à-dire la moyenne l’entropie croisée sur l’ensemble de la base d’apprentissage $ \\mathcal{D} $ constituée des $ N=60000 $ images :\n",
    "\n",
    "\n",
    "<a id='equation-ce'></a>\n",
    "$$\n",
    "\\mathcal{L}_{\\mathbf{W},\\mathbf{b}}(\\mathcal{D})  = - \\frac{1}{N}\\sum_{i=1}^{N} \\log(\\hat{y}_{c^*,i}) \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c947826",
   "metadata": {},
   "source": [
    "### Optimisation du modèle\n",
    "\n",
    "Nous allons minimiser la fonction de coût à l’aide de l’algorithme de descente de gradient appliqué sur les paramètres $ \\mathbf{W} $ et $ \\mathbf{b} $ du modèle de régression logistique. Pour ce faire, nous allons avoir besoin des gradients de l’entropie croisée par rapport à $ \\mathbf{W} $ ainsi que $ \\mathbf{b} $. Nous pouvons nous appuyer sur la des dérivées chaînées (*chain rule*, ou théorème de dérivation des fonctions composées) :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}} =  \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{\\hat{y_i}}}  \\frac{\\partial \\mathbf{\\hat{y_i}}}{\\partial \\mathbf{s_i}} \\frac{\\partial \\mathbf{s_i}}{\\partial \\mathbf{W}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}} =  \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{\\hat{y_i}}}  \\frac{\\partial \\mathbf{\\hat{y_i}}}{\\partial \\mathbf{s_i}} \\frac{\\partial \\mathbf{s_i}}{\\partial \\mathbf{b}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d7802",
   "metadata": {},
   "source": [
    "### Implémentation de l’apprentissage\n",
    "\n",
    "Les gradients obtenus par les équations du gradients s’écrivent sous forme « vectorielle », ce qui rend les calculs efficaces avec des bibliothèques de calcul scientifique telles que `numpy`. Après calcul du gradient, les paramètres sont mis à jour de la façon suivante :\n",
    "\n",
    "\n",
    "<a id='equation-gradientupdatew'></a>\n",
    "$$\n",
    "\\mathbf{W}^{(t+1)} = \\mathbf{W}^{(t)} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}} \\tag{6}\n",
    "$$\n",
    "\n",
    "\n",
    "<a id='equation-gradientupdateb'></a>\n",
    "$$\n",
    "\\mathbf{b}^{(t+1)} = \\mathbf{b}^{(t)} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}} \\tag{7}\n",
    "$$\n",
    "\n",
    "où $ \\eta $ est le pas de gradient (*learning rate*).\n",
    "\n",
    "En théorie, la descente de gradient nécessite de calculer les gradients de la fonction de coût sur tout le jeu de données d’apprentissage. Toutefois, ce jeu de données est assez grand et les gradients peuvent être longs à calculer. En pratique, on implémente plutôt une descente de gradient *stochastique*, c’est à dire que les gradients aux équations [(4)](#equation-gradientw) et [(5)](#equation-gradientb) ne seront pas calculés sur l’ensemble des $ N=60000 $ images d’apprentissage, mais sur un sous-ensemble de $ n $ images appelé *batch* ou *lot*. Cette technique permet une mise à jour des paramètres plus fréquente qu’avec une descente de gradient classique, un temps de calcul réduit et une convergence plus rapide, au détriment d’une approximation du gradient.\n",
    "\n",
    "Le code ci-dessous décrit le squelette de l’algorithme de descente de gradient qui va permettre l’optimisation des paramètres du modèle :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95891c86-3b4f-4309-a99f-8300411865d1",
   "metadata": {},
   "source": [
    "Ce dessous quelques indices :\n",
    "\n",
    "---\n",
    "\n",
    "## **🔹 Explication du code**\n",
    "Le programme entraîne un **modèle de classification linéaire** en utilisant **la descente de gradient par mini-batch**. Il apprend à **prédire des classes** à partir de données d'entrée en utilisant une **fonction de perte cross-entropy** et une **fonction d'activation softmax**.\n",
    "\n",
    "### **1️⃣ Forward Pass (Prédiction)**\n",
    "On calcule les scores bruts des classes :\n",
    "$$\n",
    "\\text{logits} = XW + b\n",
    "$$\n",
    "Puis, on applique la **fonction softmax** pour obtenir des probabilités.\n",
    "\n",
    "### **2️⃣ Calcul de la perte (Cross-Entropy)**\n",
    "- On transforme les étiquettes (`y_batch`) en **one-hot encoding**.\n",
    "- On utilise la **perte d'entropie croisée** :\n",
    "  $$\n",
    "  \\text{Perte} = -\\frac{1}{N} \\sum_{i} y_i \\log(\\hat{y}_i)\n",
    "  $$\n",
    "\n",
    "### **3️⃣ Backward Pass (Calcul des gradients)**\n",
    "- Le gradient de la perte par rapport aux logits est donné par :\n",
    "  $$\n",
    "  dL/d\\hat{Y} = \\hat{Y} - Y_{\\text{one-hot}}\n",
    "  $$\n",
    "- Ensuite, on calcule les gradients par rapport à **W** et **b**.\n",
    "\n",
    "### **4️⃣ Mise à jour des paramètres (Descente de Gradient)**\n",
    "- On met à jour `W` et `b` en soustrayant le gradient multiplié par le **taux d'apprentissage (eta)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009d1ef-4634-4cfd-a5e5-e083586f7484",
   "metadata": {},
   "source": [
    "#### ** --> Formules des gradients de W et b**  \n",
    "\n",
    "##### **Gradient par rapport à W (gradW)**\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W} = \\frac{1}{m} X^T (\\hat{Y} - Y)\n",
    "$$\n",
    "\n",
    "- $ X^T $ est la transposée de la matrice des entrées.  \n",
    "- $ (\\hat{Y} - Y) $ représente la différence entre la prédiction et la vraie étiquette.\n",
    "\n",
    "##### **Gradient par rapport à b (gradb)**\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{Y}_i - Y_i)\n",
    "$$\n",
    "- Il s'agit simplement de la somme des erreurs sur chaque échantillon du batch.\n",
    "\n",
    "---\n",
    "\n",
    "#### **📌 Mise à jour des paramètres**\n",
    "Une fois les gradients calculés, on met à jour les paramètres via la **descente de gradient** :\n",
    "$$\n",
    "W = W - \\eta \\frac{\\partial L}{\\partial W}\n",
    "$$\n",
    "$$\n",
    "b = b - \\eta \\frac{\\partial L}{\\partial b}\n",
    "$$\n",
    "\n",
    "où $ \\eta $ est le **taux d'apprentissage** (learning rate).\n",
    "\n",
    "##### **✅ Résumé**\n",
    "| Gradient | Formule mathématique |\n",
    "|----------|---------------------|\n",
    "| $ \\frac{\\partial L}{\\partial W} $ | $ \\frac{1}{m} X^T (\\hat{Y} - Y) $ |\n",
    "| $ \\frac{\\partial L}{\\partial b} $ | $ \\frac{1}{m} \\sum (\\hat{Y} - Y) $ |\n",
    "| Mise à jour de $ W $ | $ W = W - \\eta \\cdot \\frac{\\partial L}{\\partial W} $ |\n",
    "| Mise à jour de $ b $ | $ b = b - \\eta \\cdot \\frac{\\partial L}{\\partial b} $ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e1f27ead",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "N, d = X_train.shape # N exemples, dimension d\n",
    "W = np.zeros((d, n_classes)) # initialisation de poids\n",
    "b = np.zeros((1, n_classes)) # initialisation des biais\n",
    "\n",
    "n_epochs = 20 # Nombre d'epochs de la descente de gradient\n",
    "eta = 1e-1 # Learning rate (pas d'apprentissage)\n",
    "batch_size = 100 # Taille du lot\n",
    "n_batches = int(float(N) / batch_size)\n",
    "\n",
    "# On alloue deux matrices pour stocker les valeurs des gradients\n",
    "gradW = np.zeros((d, n_classes))\n",
    "gradb = np.zeros((1, n_classes))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx in range(n_batches):\n",
    "        # ********* À compléter **********\n",
    "        # Sélection du mini-batch\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = X_train[start:end]  # Sélection des entrées du mini-batch\n",
    "        y_batch = y_train[start:end]  # Sélection des labels du mini-batch\n",
    "\n",
    "        # ---- FORWARD PASS ----\n",
    "        logits = X_batch @ W + b  # Calcul des scores bruts (logits)\n",
    "        softmax_probs = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True) # Conversion en probabilités\n",
    "\n",
    "        # ---- CALCUL DE LA PERTE (CROSS-ENTROPY) ----\n",
    "        one_hot_y = np.eye(n_classes)[y_batch]  # Conversion des labels en one-hot encoding\n",
    "        y_log_y_pred = one_hot_y * np.log(softmax_probs + 1e-9) # Ajout d'un petit terme pour éviter log(0)\n",
    "        loss = -np.sum(y_log_y_pred) / batch_size\n",
    "\n",
    "        # ---- BACKWARD PASS ----\n",
    "        dL_dlogits = softmax_probs - one_hot_y  # Gradient de la perte par rapport aux logits\n",
    "        gradW = np.dot(X_batch.T, dL_dlogits) / batch_size  # Gradient par rapport à W\n",
    "        gradb = np.sum(dL_dlogits, axis=0, keepdims=True) / batch_size  # Gradient par rapport à b\n",
    "        \n",
    "        # ---- MISE À JOUR DES PARAMÈTRES ----\n",
    "        W -= eta * gradW\n",
    "        b -= eta * gradb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb04541",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Compléter ce code. Vous devez notamment :\n",
    "\n",
    "> - Écrire une fonction `forward(batch, W, b)` qui calcule la prédiction (vecteur de sortie $ \\hat{\\mathbf{y}} $ pour chaque exemple d’un batch de données. Si on considère un batch des données de taille $ tb\\times 784 $, les paramètres $ \\mathbf{W} $ (taille $ 784\\times 10 $) et $ \\mathbf{b} $ (taille $ 1\\times 10 $), la fonction `forward` renvoie la prédiction $ \\mathbf{\\hat{Y}} $ sur le batch (taille $ tb\\times 10 $).  La fonction `forward` sera appelée pour chaque itération de la double boucle précédente.  \n",
    "- Completer la fonction `softmax` ci-dessous pour calculer le résultat du passage du softmax sur chaque élément de de la matrice de la projection linéraire (taille $ tb\\times 10 $) :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65d5b373-b44e-4dc9-80e2-f397a12afebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X_batch, W, b ):\n",
    "    \n",
    "    logits = X_batch @ W + b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "806ef32d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "     # Entrée: matrice X de dimensions batch x d\n",
    "     # Sortie: matrice de mêmes dimensions\n",
    "     softmax_probs = np.exp(X) / np.sum(np.exp(X), axis=1, keepdims=True) # Conversion en probabilités\n",
    "     return softmax_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa6c02",
   "metadata": {},
   "source": [
    "\n",
    "- \n",
    "  <dl style='margin: 20px 0;'>\n",
    "  <dt>réecrire le code d'avant avec les deux nouvelles fonctions</dt>\n",
    "  \n",
    "  </dl>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "976cd5e6-cc07-4217-bb80-b68e48a080ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "N, d = X_train.shape # N exemples, dimension d\n",
    "W = np.zeros((d, n_classes)) # initialisation de poids\n",
    "b = np.zeros((1, n_classes)) # initialisation des biais\n",
    "\n",
    "n_epochs = 20 # Nombre d'epochs de la descente de gradient\n",
    "eta = 1e-1 # Learning rate (pas d'apprentissage)\n",
    "batch_size = 100 # Taille du lot\n",
    "n_batches = int(float(N) / batch_size)\n",
    "\n",
    "# On alloue deux matrices pour stocker les valeurs des gradients\n",
    "gradW = np.zeros((d, n_classes))\n",
    "gradb = np.zeros((1, n_classes))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx in range(n_batches):\n",
    "        # ********* À compléter **********\n",
    "        # Sélection du mini-batch\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = X_train[start:end]  # Sélection des entrées du mini-batch\n",
    "        y_batch = y_train[start:end]  # Sélection des labels du mini-batch\n",
    "\n",
    "        # ---- FORWARD PASS ----\n",
    "        logits = forward(X_batch, W, b)  # Calcul des scores bruts (logits)\n",
    "        softmax_probs = softmax(logits) # Conversion en probabilités\n",
    "\n",
    "        # ---- CALCUL DE LA PERTE (CROSS-ENTROPY) ----\n",
    "        one_hot_y = np.eye(n_classes)[y_batch]  # Conversion des labels en one-hot encoding\n",
    "        y_log_y_pred = one_hot_y * np.log(softmax_probs + 1e-9) # Ajout d'un petit terme pour éviter log(0)\n",
    "        loss = -np.sum(y_log_y_pred) / batch_size\n",
    "\n",
    "        # ---- BACKWARD PASS ----\n",
    "        dL_dlogits = softmax_probs - one_hot_y  # Gradient de la perte par rapport aux logits\n",
    "        gradW = np.dot(X_batch.T, dL_dlogits) / batch_size  # Gradient par rapport à W\n",
    "        gradb = np.sum(dL_dlogits, axis=0, keepdims=True) / batch_size  # Gradient par rapport à b\n",
    "        \n",
    "        # ---- MISE À JOUR DES PARAMÈTRES ----\n",
    "        W -= eta * gradW\n",
    "        b -= eta * gradb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef8bff",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Évaluer les performances du modèle de régression logistique entraîné sur MNIST. On utilisera le taux de bonne classification (*accuracy*) comme métrique. Commencer par mesurer l’évolution des performances du modèle au cours de l’apprentissage (calcul de l'*accuracy* à chaque époque), puis évaluer sur le modèle sur la base de test. Vous pouvez utiliser la [fonction de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) ou la fonction `accuracy` ci-dessous (qui effectue également la phase de prédiction).\n",
    "\n",
    "**Vous devriez obtenir un score de l’ordre de 92% sur la base de test pour ce modèle de régression logistique.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ea5de83",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def accuracy(W, b, images, labels):\n",
    "    \"\"\" W: matrice de paramètres\n",
    "        b: vecteur de biais\n",
    "        images: images de MNIST\n",
    "        labels: étiquettes de MNIST pour les images\n",
    "\n",
    "        Renvoie l'accuracy du modèle (W, b) sur les images par rapport aux labels\n",
    "    \"\"\"\n",
    "    pred = forward(images, W, b)\n",
    "    return np.where(pred.argmax(axis=1) != labels.argmax(axis=1), 0.,1.).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af6dd0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9224"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(W, b, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2abc1be-8b96-4888-ad03-8598883b8b07",
   "metadata": {},
   "source": [
    "##### Utilise le package sklearn pour entraîner un MLP (avec la même architecture que le réseau précédent) ainsi qu’un SVM. Évalue ensuite les deux modèles et compare les résultats obtenus avec ceux du modèle précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f440de9-b250-4321-8ebe-592c12beceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy avec MLP :  0.9767\n"
     ]
    }
   ],
   "source": [
    "#Essai avec MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "clf = MLPClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy avec MLP : \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b03f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian-andr/anaconda3/envs/jpn_florian/lib/python3.8/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy avec SVM : 0.7962\n"
     ]
    }
   ],
   "source": [
    "#Essai avec SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy avec SVM :\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ad234",
   "metadata": {},
   "source": [
    "On remarque que sur les 3 modèles, le premier (réseau de neurones avec Régression logistique) a l'accuracy la moins élevée (0.92) mais il est le plus rapide à entraîner (moins de 30 secondes)\n",
    "Le modèle avec SVM a l'accuracy la plus élevée (0,9792) mais c'est aussi le plus long à entraîner (plus de 4 minutes)"
   ]
  }
 ],
 "metadata": {
  "date": 1725613532.7446063,
  "filename": "tpDeepLearning1.rst",
  "kernelspec": {
   "display_name": "jpn_florian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "title": "Travaux pratiques - Premiers réseaux de neurones"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
