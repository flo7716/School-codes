{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840f55de",
   "metadata": {},
   "source": [
    "\n",
    "<a id='chap-tpdeeplearning1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d6084",
   "metadata": {},
   "source": [
    "# Travaux pratiques - Premiers r√©seaux de neurones\n",
    "\n",
    "Au cours de cette s√©ance de travaux pratiques, vous allez √™tre amen√©s √† impl√©menter vous-m√™me l‚Äôapprentissage d‚Äôun r√©seau de neurones simple. Bien que de nombreuses biblioth√®ques existent pour automatiser cette t√¢che, il est tr√®s utile de se familiariser avec les concepts fondamentaux au moins une fois. Cela vous permettra d‚Äôavoir une meilleure compr√©hension des outils que nous utiliserons plus tard, comme Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79b434",
   "metadata": {},
   "source": [
    "## Jeu de donn√©es MNIST\n",
    "\n",
    "Lors de cette s√©ance, nous allons utiliser la base de donn√©es MNIST, compos√©e de 70 000 images de chiffres manuscrits en noir et blanc (60 000 pour l‚Äôentra√Ænement et 10 000 pour le test). L‚Äôobjectif est de d√©velopper un mod√®le capable d‚Äôidentifier automatiquement le chiffre √† partir de chaque image.\n",
    "\n",
    "Pour commencer, nous allons importer les donn√©es. √âtant donn√© qu‚Äôil s‚Äôagit d‚Äôun jeu de donn√©es largement utilis√© et standard, il est int√©gr√© dans plusieurs biblioth√®ques, comme Keras, ce qui nous permet de l‚Äôimporter facilement en une seule ligne de code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b977c142-6bfc-4471-8e6b-481c2949a723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: keras in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (2.13.1)\n",
      "Collecting keras\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: numpy in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (1.24.3)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: scipy in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (1.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (1.69.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./anaconda3/envs/jpn_florian/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow keras numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9290b648-c045-4ca6-b8f7-df1acb7e5f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/florian-andr/anaconda3/envs/jpn_florian/bin/python\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import sys; print(sys.executable)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2b4807a-9c84-4f8c-8165-2fa4110239d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show numpy\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3220bff",
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 exemples d'apprentissage\n",
      "10000 exemples de test\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# Import de MNIST depuis Keras\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# Transformation des images 28x28 en vecteur de dimension 784\n",
    "X_train = X_train.reshape(60000, 784).astype('float32')\n",
    "X_test = X_test.reshape(10000, 784).astype('float32')\n",
    "# Normalisation entre 0 et 1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Affichage du nombre de'exemples\n",
    "print(f\"{X_train.shape[0]} exemples d'apprentissage\")\n",
    "print(f\"{X_test.shape[0]} exemples de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb0017",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Afficher √† l‚Äôaide de matplotlib les premi√®res images du jeu d‚Äôapprentissage. La fonction `plt.imshow()` (cf. [sa documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html)) peut vous √™tre utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccf7b9f9-9cdb-4ebe-85cf-84c1d78d16e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "n_images = 10\n",
    "for i in range(n_images):\n",
    "    plt.subplot(1, n_images, i+1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0f2f2",
   "metadata": {},
   "source": [
    "## Question :\n",
    "\n",
    "Quel est l‚Äôespace dans lequel se trouvent les images ? Quelle est sa dimension ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c82065f2-be15-4ec6-b8cd-b8cb01ab5898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c58781",
   "metadata": {},
   "source": [
    "## R√©gression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b020534b",
   "metadata": {},
   "source": [
    "### Mod√®le de pr√©diction\n",
    "\n",
    "Nous allons impl√©menter un mod√®le de classification lin√©aire simple : la r√©gression logistique. Concr√®tement, la r√©gression logistique est √©quivalente √† un r√©seau de neurones √† une seule couche. Il s‚Äôagit d‚Äôune projection du vecteur d‚Äôentr√©e $ \\mathbf{x_i} $ par un vecteur de param√®tres $ \\mathbf{w_{c}} $, plus un biais sclaaire $ b_c $, pour chaque classe.  Le sch√©ma ci-dessous illustre le mod√®le de r√©gression logistique avec un r√©seau de neurones.\n",
    "\n",
    "<img src=\"LR.png\" style=\"height:150px;\" align=\"center\">\n",
    "\n",
    "En l‚Äôoccurrence, pour MNIST $ \\mathbf{x}_i $ est de dimension 784 et il y a dix chiffres possibles, donc 10 classes diff√©rentes. Dans notre cas, on consid√®re que l‚Äôimage d‚Äôentr√©e est repr√©sent√©e sous sa forme ¬´ aplatie ¬ª, c‚Äôest-√†-dire un vecteur (1, 784).\n",
    "\n",
    "Pour simplifier les notations, on regroupe l‚Äôensemble des jeux de param√®tres $ \\mathbf{w_{c}} $ pour les 10 classes possibles dans une unique matrice $ \\mathbf{W} $ de dimensions $ 784\\times 10 $. De la m√™me fa√ßon, les biais sont regroup√©s dans un vecteur $ \\mathbf{b} $ de longueur 10. La sortie de la r√©gression logistique est un vecteur contenant une activation pour chaque classe, c‚Äôest-√†-dire $ \\mathbf{\\hat{s_i}} =\\mathbf{x_i}  \\mathbf{W}  + \\mathbf{b} $ de dimensions (1, 10).\n",
    "\n",
    "Afin de transformer les activations en de sortie en probabilit√©s pour une distribution cat√©gorielle, on ajoute une fonction d‚Äôactivation de *softmax* sur $ \\mathbf{\\hat{y_i}} = \\sigma(\\mathbf{s_i}) $. Cela nous permet d‚Äôobtenir en sortie un vecteur de pr√©dictions $ \\mathbf{\\hat{y_i}} $, de dimensions (1, 10),  qui repr√©sente la probabilit√© *a posteriori* $ p(\\mathbf{\\hat{y_i}} | \\mathbf{x_i}) $ pour chacune des 10 classes :\n",
    "\n",
    "\n",
    "<a id='equation-softmax'></a>\n",
    "$$\n",
    "p(\\hat{y}_{c,i} | \\mathbf{x_i}) ) = \\frac{e^{\\langle \\mathbf{x_i} ; \\mathbf{w_{c}}\\rangle + b_{c}}}{\\sum_{c'=1}^{10} e^{\\langle \\mathbf{x_i} ; \\mathbf{w_{c'}}\\rangle + b_{c'}}} \\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15508582",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Quel est le nombre de param√®tres du mod√®le utilis√© ? Justifier le calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec43ebb3-8de7-4183-875c-5e9223559cc6",
   "metadata": {},
   "source": [
    "\"784 * 10 + 10 = 7850 param√®tres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16936d3e",
   "metadata": {},
   "source": [
    "### Formulation du probl√®me d‚Äôapprentissage\n",
    "\n",
    "Pour entra√Æner le r√©seau de neurones, c‚Äôest-√†-dire d√©terminer les valeurs optimales des param√®tres $ \\mathbf{W} $ et $ \\mathbf{b} $, on va comparer pour chaque exemple d‚Äôapprentissage la sortie pr√©dite $ \\mathbf{\\hat{y_i}} $ (√©quation [(1)](#equation-softmax)) pour l‚Äôimage $ \\mathbf{x_i} $ √† la sortie r√©elle $ \\mathbf{y_i^*} $ (v√©rit√© terrain issue de la supervision). Dans notre cas, on choisit d‚Äôencoder la cat√©gorie de l‚Äôimage $ \\mathbf{x_i} $ sous forme *one-hot*, c‚Äôest-√†-dire :\n",
    "\n",
    "\n",
    "<a id='equation-one-hot'></a>\n",
    "$$\n",
    "y_{c,i}^* =\n",
    " \\begin{cases}\n",
    "   1 & \\text{si c correspond √† l'indice de la classe de } \\mathbf{x_i}  \\\\\n",
    "   0 & \\text{sinon}\n",
    " \\end{cases} \\tag{2}\n",
    "$$\n",
    "\n",
    "G√©n√©rons les √©tiquettes (*labels*) au format *one-hot* ([(2)](#equation-one-hot)) √† l‚Äôaide de la fonction `to_categorical` (cf. [documentation de Keras](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b514892",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "n_classes = 10\n",
    "# Conversion des √©tiquettes (int) au format vectoriel one-hot\n",
    "Y_train = to_categorical(y_train, n_classes)\n",
    "Y_test = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5e911",
   "metadata": {},
   "source": [
    "L‚Äôerreur de pr√©diction sera d√©finie √† l‚Äôaide de l‚Äôentropie crois√©e (*cross-entropy*). Cette fonction de co√ªt s‚Äôapplique entre $ \\mathbf{\\hat{y_i}} $ et $ \\mathbf{y_i^*} $ par la formule:\n",
    "$ \\mathcal{L}(\\mathbf{\\hat{y_i}}, \\mathbf{y_i^*}) = -\\sum_{c=1}^{10} y_{c,i}^* \\log(\\hat{y}_{c,i}) = - \\log(\\hat{y}_{c^*,i}) $, o√π $ c^* $ correspond √† l‚Äôindice de la classe donn√©e par la supervision pour l‚Äôimage $ \\mathbf{x_i} $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b5186",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "L‚Äôentropie crois√©e correspond en r√©alit√© √† la divergence de Kullback-Leiber pour des distributions cat√©gorielles. La divergence KL est une mesure de dissimilarit√© entre distributions de probabilit√©. Autrement dit, l‚Äôerreur que l‚Äôon mesure vise √† r√©duire l‚Äô√©cart entre la distribution r√©elle des cat√©gories et la distribution pr√©dite.\n",
    "\n",
    "La fonction de co√ªt finale correspond √† l‚Äôerreur d‚Äôapprentissage, c‚Äôest-√†-dire la moyenne l‚Äôentropie crois√©e sur l‚Äôensemble de la base d‚Äôapprentissage $ \\mathcal{D} $ constitu√©e des $ N=60000 $ images :\n",
    "\n",
    "\n",
    "<a id='equation-ce'></a>\n",
    "$$\n",
    "\\mathcal{L}_{\\mathbf{W},\\mathbf{b}}(\\mathcal{D})  = - \\frac{1}{N}\\sum_{i=1}^{N} \\log(\\hat{y}_{c^*,i}) \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c947826",
   "metadata": {},
   "source": [
    "### Optimisation du mod√®le\n",
    "\n",
    "Nous allons minimiser la fonction de co√ªt √† l‚Äôaide de l‚Äôalgorithme de descente de gradient appliqu√© sur les param√®tres $ \\mathbf{W} $ et $ \\mathbf{b} $ du mod√®le de r√©gression logistique. Pour ce faire, nous allons avoir besoin des gradients de l‚Äôentropie crois√©e par rapport √† $ \\mathbf{W} $ ainsi que $ \\mathbf{b} $. Nous pouvons nous appuyer sur la des d√©riv√©es cha√Æn√©es (*chain rule*, ou th√©or√®me de d√©rivation des fonctions compos√©es) :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}} =  \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{\\hat{y_i}}}  \\frac{\\partial \\mathbf{\\hat{y_i}}}{\\partial \\mathbf{s_i}} \\frac{\\partial \\mathbf{s_i}}{\\partial \\mathbf{W}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}} =  \\frac{1}{N}\\sum_{i=1}^{N} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{\\hat{y_i}}}  \\frac{\\partial \\mathbf{\\hat{y_i}}}{\\partial \\mathbf{s_i}} \\frac{\\partial \\mathbf{s_i}}{\\partial \\mathbf{b}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d7802",
   "metadata": {},
   "source": [
    "### Impl√©mentation de l‚Äôapprentissage\n",
    "\n",
    "Les gradients obtenus par les √©quations du gradients s‚Äô√©crivent sous forme ¬´ vectorielle ¬ª, ce qui rend les calculs efficaces avec des biblioth√®ques de calcul scientifique telles que `numpy`. Apr√®s calcul du gradient, les param√®tres sont mis √† jour de la fa√ßon suivante :\n",
    "\n",
    "\n",
    "<a id='equation-gradientupdatew'></a>\n",
    "$$\n",
    "\\mathbf{W}^{(t+1)} = \\mathbf{W}^{(t)} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}} \\tag{6}\n",
    "$$\n",
    "\n",
    "\n",
    "<a id='equation-gradientupdateb'></a>\n",
    "$$\n",
    "\\mathbf{b}^{(t+1)} = \\mathbf{b}^{(t)} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}} \\tag{7}\n",
    "$$\n",
    "\n",
    "o√π $ \\eta $ est le pas de gradient (*learning rate*).\n",
    "\n",
    "En th√©orie, la descente de gradient n√©cessite de calculer les gradients de la fonction de co√ªt sur tout le jeu de donn√©es d‚Äôapprentissage. Toutefois, ce jeu de donn√©es est assez grand et les gradients peuvent √™tre longs √† calculer. En pratique, on impl√©mente plut√¥t une descente de gradient *stochastique*, c‚Äôest √† dire que les gradients aux √©quations [(4)](#equation-gradientw) et [(5)](#equation-gradientb) ne seront pas calcul√©s sur l‚Äôensemble des $ N=60000 $ images d‚Äôapprentissage, mais sur un sous-ensemble de $ n $ images appel√© *batch* ou *lot*. Cette technique permet une mise √† jour des param√®tres plus fr√©quente qu‚Äôavec une descente de gradient classique, un temps de calcul r√©duit et une convergence plus rapide, au d√©triment d‚Äôune approximation du gradient.\n",
    "\n",
    "Le code ci-dessous d√©crit le squelette de l‚Äôalgorithme de descente de gradient qui va permettre l‚Äôoptimisation des param√®tres du mod√®le :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95891c86-3b4f-4309-a99f-8300411865d1",
   "metadata": {},
   "source": [
    "Ce dessous quelques indices :\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Explication du code**\n",
    "Le programme entra√Æne un **mod√®le de classification lin√©aire** en utilisant **la descente de gradient par mini-batch**. Il apprend √† **pr√©dire des classes** √† partir de donn√©es d'entr√©e en utilisant une **fonction de perte cross-entropy** et une **fonction d'activation softmax**.\n",
    "\n",
    "### **1Ô∏è‚É£ Forward Pass (Pr√©diction)**\n",
    "On calcule les scores bruts des classes :\n",
    "$$\n",
    "\\text{logits} = XW + b\n",
    "$$\n",
    "Puis, on applique la **fonction softmax** pour obtenir des probabilit√©s.\n",
    "\n",
    "### **2Ô∏è‚É£ Calcul de la perte (Cross-Entropy)**\n",
    "- On transforme les √©tiquettes (`y_batch`) en **one-hot encoding**.\n",
    "- On utilise la **perte d'entropie crois√©e** :\n",
    "  $$\n",
    "  \\text{Perte} = -\\frac{1}{N} \\sum_{i} y_i \\log(\\hat{y}_i)\n",
    "  $$\n",
    "\n",
    "### **3Ô∏è‚É£ Backward Pass (Calcul des gradients)**\n",
    "- Le gradient de la perte par rapport aux logits est donn√© par :\n",
    "  $$\n",
    "  dL/d\\hat{Y} = \\hat{Y} - Y_{\\text{one-hot}}\n",
    "  $$\n",
    "- Ensuite, on calcule les gradients par rapport √† **W** et **b**.\n",
    "\n",
    "### **4Ô∏è‚É£ Mise √† jour des param√®tres (Descente de Gradient)**\n",
    "- On met √† jour `W` et `b` en soustrayant le gradient multipli√© par le **taux d'apprentissage (eta)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009d1ef-4634-4cfd-a5e5-e083586f7484",
   "metadata": {},
   "source": [
    "#### ** --> Formules des gradients de W et b**  \n",
    "\n",
    "##### **Gradient par rapport √† W (gradW)**\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W} = \\frac{1}{m} X^T (\\hat{Y} - Y)\n",
    "$$\n",
    "\n",
    "- $ X^T $ est la transpos√©e de la matrice des entr√©es.  \n",
    "- $ (\\hat{Y} - Y) $ repr√©sente la diff√©rence entre la pr√©diction et la vraie √©tiquette.\n",
    "\n",
    "##### **Gradient par rapport √† b (gradb)**\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{Y}_i - Y_i)\n",
    "$$\n",
    "- Il s'agit simplement de la somme des erreurs sur chaque √©chantillon du batch.\n",
    "\n",
    "---\n",
    "\n",
    "#### **üìå Mise √† jour des param√®tres**\n",
    "Une fois les gradients calcul√©s, on met √† jour les param√®tres via la **descente de gradient** :\n",
    "$$\n",
    "W = W - \\eta \\frac{\\partial L}{\\partial W}\n",
    "$$\n",
    "$$\n",
    "b = b - \\eta \\frac{\\partial L}{\\partial b}\n",
    "$$\n",
    "\n",
    "o√π $ \\eta $ est le **taux d'apprentissage** (learning rate).\n",
    "\n",
    "##### **‚úÖ R√©sum√©**\n",
    "| Gradient | Formule math√©matique |\n",
    "|----------|---------------------|\n",
    "| $ \\frac{\\partial L}{\\partial W} $ | $ \\frac{1}{m} X^T (\\hat{Y} - Y) $ |\n",
    "| $ \\frac{\\partial L}{\\partial b} $ | $ \\frac{1}{m} \\sum (\\hat{Y} - Y) $ |\n",
    "| Mise √† jour de $ W $ | $ W = W - \\eta \\cdot \\frac{\\partial L}{\\partial W} $ |\n",
    "| Mise √† jour de $ b $ | $ b = b - \\eta \\cdot \\frac{\\partial L}{\\partial b} $ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e1f27ead",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "N, d = X_train.shape # N exemples, dimension d\n",
    "W = np.zeros((d, n_classes)) # initialisation de poids\n",
    "b = np.zeros((1, n_classes)) # initialisation des biais\n",
    "\n",
    "n_epochs = 20 # Nombre d'epochs de la descente de gradient\n",
    "eta = 1e-1 # Learning rate (pas d'apprentissage)\n",
    "batch_size = 100 # Taille du lot\n",
    "n_batches = int(float(N) / batch_size)\n",
    "\n",
    "# On alloue deux matrices pour stocker les valeurs des gradients\n",
    "gradW = np.zeros((d, n_classes))\n",
    "gradb = np.zeros((1, n_classes))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx in range(n_batches):\n",
    "        # ********* √Ä compl√©ter **********\n",
    "        # S√©lection du mini-batch\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = X_train[start:end]  # S√©lection des entr√©es du mini-batch\n",
    "        y_batch = y_train[start:end]  # S√©lection des labels du mini-batch\n",
    "\n",
    "        # ---- FORWARD PASS ----\n",
    "        logits = X_batch @ W + b  # Calcul des scores bruts (logits)\n",
    "        softmax_probs = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True) # Conversion en probabilit√©s\n",
    "\n",
    "        # ---- CALCUL DE LA PERTE (CROSS-ENTROPY) ----\n",
    "        one_hot_y = np.eye(n_classes)[y_batch]  # Conversion des labels en one-hot encoding\n",
    "        y_log_y_pred = one_hot_y * np.log(softmax_probs + 1e-9) # Ajout d'un petit terme pour √©viter log(0)\n",
    "        loss = -np.sum(y_log_y_pred) / batch_size\n",
    "\n",
    "        # ---- BACKWARD PASS ----\n",
    "        dL_dlogits = softmax_probs - one_hot_y  # Gradient de la perte par rapport aux logits\n",
    "        gradW = np.dot(X_batch.T, dL_dlogits) / batch_size  # Gradient par rapport √† W\n",
    "        gradb = np.sum(dL_dlogits, axis=0, keepdims=True) / batch_size  # Gradient par rapport √† b\n",
    "        \n",
    "        # ---- MISE √Ä JOUR DES PARAM√àTRES ----\n",
    "        W -= eta * gradW\n",
    "        b -= eta * gradb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb04541",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Compl√©ter ce code. Vous devez notamment :\n",
    "\n",
    "> - √âcrire une fonction `forward(batch, W, b)` qui calcule la pr√©diction (vecteur de sortie $ \\hat{\\mathbf{y}} $ pour chaque exemple d‚Äôun batch de donn√©es. Si on consid√®re un batch des donn√©es de taille $ tb\\times 784 $, les param√®tres $ \\mathbf{W} $ (taille $ 784\\times 10 $) et $ \\mathbf{b} $ (taille $ 1\\times 10 $), la fonction `forward` renvoie la pr√©diction $ \\mathbf{\\hat{Y}} $ sur le batch (taille $ tb\\times 10 $).  La fonction `forward` sera appel√©e pour chaque it√©ration de la double boucle pr√©c√©dente.  \n",
    "- Completer la fonction `softmax` ci-dessous pour calculer le r√©sultat du passage du softmax sur chaque √©l√©ment de de la matrice de la projection lin√©raire (taille $ tb\\times 10 $) :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65d5b373-b44e-4dc9-80e2-f397a12afebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X_batch, W, b ):\n",
    "    \n",
    "    logits = X_batch @ W + b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "806ef32d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "     # Entr√©e: matrice X de dimensions batch x d\n",
    "     # Sortie: matrice de m√™mes dimensions\n",
    "     softmax_probs = np.exp(X) / np.sum(np.exp(X), axis=1, keepdims=True) # Conversion en probabilit√©s\n",
    "     return softmax_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa6c02",
   "metadata": {},
   "source": [
    "\n",
    "- \n",
    "  <dl style='margin: 20px 0;'>\n",
    "  <dt>r√©ecrire le code d'avant avec les deux nouvelles fonctions</dt>\n",
    "  \n",
    "  </dl>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "976cd5e6-cc07-4217-bb80-b68e48a080ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "N, d = X_train.shape # N exemples, dimension d\n",
    "W = np.zeros((d, n_classes)) # initialisation de poids\n",
    "b = np.zeros((1, n_classes)) # initialisation des biais\n",
    "\n",
    "n_epochs = 20 # Nombre d'epochs de la descente de gradient\n",
    "eta = 1e-1 # Learning rate (pas d'apprentissage)\n",
    "batch_size = 100 # Taille du lot\n",
    "n_batches = int(float(N) / batch_size)\n",
    "\n",
    "# On alloue deux matrices pour stocker les valeurs des gradients\n",
    "gradW = np.zeros((d, n_classes))\n",
    "gradb = np.zeros((1, n_classes))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx in range(n_batches):\n",
    "        # ********* √Ä compl√©ter **********\n",
    "        # S√©lection du mini-batch\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = X_train[start:end]  # S√©lection des entr√©es du mini-batch\n",
    "        y_batch = y_train[start:end]  # S√©lection des labels du mini-batch\n",
    "\n",
    "        # ---- FORWARD PASS ----\n",
    "        logits = forward(X_batch, W, b)  # Calcul des scores bruts (logits)\n",
    "        softmax_probs = softmax(logits) # Conversion en probabilit√©s\n",
    "\n",
    "        # ---- CALCUL DE LA PERTE (CROSS-ENTROPY) ----\n",
    "        one_hot_y = np.eye(n_classes)[y_batch]  # Conversion des labels en one-hot encoding\n",
    "        y_log_y_pred = one_hot_y * np.log(softmax_probs + 1e-9) # Ajout d'un petit terme pour √©viter log(0)\n",
    "        loss = -np.sum(y_log_y_pred) / batch_size\n",
    "\n",
    "        # ---- BACKWARD PASS ----\n",
    "        dL_dlogits = softmax_probs - one_hot_y  # Gradient de la perte par rapport aux logits\n",
    "        gradW = np.dot(X_batch.T, dL_dlogits) / batch_size  # Gradient par rapport √† W\n",
    "        gradb = np.sum(dL_dlogits, axis=0, keepdims=True) / batch_size  # Gradient par rapport √† b\n",
    "        \n",
    "        # ---- MISE √Ä JOUR DES PARAM√àTRES ----\n",
    "        W -= eta * gradW\n",
    "        b -= eta * gradb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef8bff",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "√âvaluer les performances du mod√®le de r√©gression logistique entra√Æn√© sur MNIST. On utilisera le taux de bonne classification (*accuracy*) comme m√©trique. Commencer par mesurer l‚Äô√©volution des performances du mod√®le au cours de l‚Äôapprentissage (calcul de l'*accuracy* √† chaque √©poque), puis √©valuer sur le mod√®le sur la base de test. Vous pouvez utiliser la [fonction de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) ou la fonction `accuracy` ci-dessous (qui effectue √©galement la phase de pr√©diction).\n",
    "\n",
    "**Vous devriez obtenir un score de l‚Äôordre de 92% sur la base de test pour ce mod√®le de r√©gression logistique.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ea5de83",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def accuracy(W, b, images, labels):\n",
    "    \"\"\" W: matrice de param√®tres\n",
    "        b: vecteur de biais\n",
    "        images: images de MNIST\n",
    "        labels: √©tiquettes de MNIST pour les images\n",
    "\n",
    "        Renvoie l'accuracy du mod√®le (W, b) sur les images par rapport aux labels\n",
    "    \"\"\"\n",
    "    pred = forward(images, W, b)\n",
    "    return np.where(pred.argmax(axis=1) != labels.argmax(axis=1), 0.,1.).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af6dd0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9224"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(W, b, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2abc1be-8b96-4888-ad03-8598883b8b07",
   "metadata": {},
   "source": [
    "##### Utilise le package sklearn pour entra√Æner un MLP (avec la m√™me architecture que le r√©seau pr√©c√©dent) ainsi qu‚Äôun SVM. √âvalue ensuite les deux mod√®les et compare les r√©sultats obtenus avec ceux du mod√®le pr√©c√©dent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f440de9-b250-4321-8ebe-592c12beceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy avec MLP :  0.9767\n"
     ]
    }
   ],
   "source": [
    "#Essai avec MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "clf = MLPClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy avec MLP : \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b03f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian-andr/anaconda3/envs/jpn_florian/lib/python3.8/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy avec SVM : 0.7962\n"
     ]
    }
   ],
   "source": [
    "#Essai avec SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy avec SVM :\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ad234",
   "metadata": {},
   "source": [
    "On remarque que sur les 3 mod√®les, le premier (r√©seau de neurones avec R√©gression logistique) a l'accuracy la moins √©lev√©e (0.92) mais il est le plus rapide √† entra√Æner (moins de 30 secondes)\n",
    "Le mod√®le avec SVM a l'accuracy la plus √©lev√©e (0,9792) mais c'est aussi le plus long √† entra√Æner (plus de 4 minutes)"
   ]
  }
 ],
 "metadata": {
  "date": 1725613532.7446063,
  "filename": "tpDeepLearning1.rst",
  "kernelspec": {
   "display_name": "jpn_florian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "title": "Travaux pratiques - Premiers r√©seaux de neurones"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
